import { env } from '../config/env';
import fetch from "node-fetch";
import { callOpenAI, callOpenAIResponseStream } from './openai';
import type { StreamEventType } from './openai';
import type OpenAI from 'openai';
import { generateStreamId, getNextSequence, writeStreamEvent } from './stream-service';

// Fonction pour Tavily Search
const TAVILY_API_KEY = env.TAVILY_API_KEY;

// Prompts d'orchestration web tools (DOIVENT rester identiques entre non-streaming et streaming)
const WEB_TOOLS_SYSTEM_PROMPT =
  "Tu es un assistant qui utilise la recherche web et l'extraction de contenu pour fournir des informations r√©centes et pr√©cises. Utilise l'outil de recherche web pour trouver des informations, puis l'outil d'extraction pour obtenir le contenu d√©taill√© des URLs pertinentes.";

const WEB_TOOLS_FOLLOWUP_SYSTEM_PROMPT =
  "Tu es un assistant qui fournit des r√©ponses bas√©es sur les r√©sultats de recherche web et les contenus extraits d'URLs.";

const WEB_TOOLS_FOLLOWUP_ASSISTANT_PROMPT =
  "Je vais rechercher et extraire des informations r√©centes pour vous.";

const WEB_TOOLS_RESULTS_SUFFIX =
  "R√©ponds √† la question originale en utilisant ces informations r√©centes.";

// Tools (d√©finition unique)
export const webSearchTool: OpenAI.Chat.Completions.ChatCompletionTool = {
  type: "function",
  function: {
    name: "web_search",
    description: "Tavily Search API for real-time web search. Use this tool to search for current information on the web.",
    parameters: {
      type: "object",
      properties: {
        query: {
          type: "string",
          description: "The search query to find relevant information"
        }
      },
      required: ["query"]
    }
  }
};

export const webExtractTool: OpenAI.Chat.Completions.ChatCompletionTool = {
  type: "function",
  function: {
    name: "web_extract",
    description: "Extract and retrieve the full content of one or more web page URLs. Use this tool to get detailed content from URLs found during web search or provided directly. You can extract multiple URLs in a single call for efficiency.",
    parameters: {
      type: "object",
      properties: {
        urls: {
          type: "array",
          items: {
            type: "string"
          },
          description: "Array of URLs to extract content from. Can be a single URL or multiple URLs."
        }
      },
      required: ["urls"]
    }
  }
};

/**
 * Tool pour lire un use case complet.
 * Retourne la structure `use_cases.data` compl√®te.
 */
export const readUseCaseTool: OpenAI.Chat.Completions.ChatCompletionTool = {
  type: "function",
  function: {
    name: "read_usecase",
    description:
      "Lit le contenu complet d'un use case (structure use_cases.data). Utilise ce tool pour conna√Ætre l'√©tat actuel avant de proposer des modifications.",
    parameters: {
      type: "object",
      properties: {
        useCaseId: { type: "string", description: "ID du use case √† lire" }
      },
      required: ["useCaseId"]
    }
  }
};

/**
 * Tool g√©n√©rique: met √† jour un ou plusieurs champs de `use_cases.data.*`.
 * Le mapping DB est pris en charge c√¥t√© `tool-service.ts`.
 */
export const updateUseCaseFieldTool: OpenAI.Chat.Completions.ChatCompletionTool = {
  type: "function",
  function: {
    name: "update_usecase_field",
    description:
      "OBLIGATOIRE : Utilise ce tool quand l'utilisateur demande de modifier, reformuler ou mettre √† jour des champs du use case. Ne r√©ponds pas dans le texte, utilise ce tool pour appliquer les modifications directement en base de donn√©es. Met √† jour un ou plusieurs champs d'un use case (JSONB use_cases.data). Utilise des paths dot-notation. Exemples de paths : 'description', 'problem', 'solution', 'solution.bullets' (pour un tableau), 'solution.bullets.0' (pour un √©l√©ment sp√©cifique).",
    parameters: {
      type: "object",
      properties: {
        useCaseId: { type: "string", description: "ID du use case √† modifier" },
        updates: {
          type: "array",
          description: "Liste des modifications √† appliquer (max 50). path cible use_cases.data.*",
          items: {
            type: "object",
            properties: {
              path: { type: "string", description: "Chemin du champ (ex: description, problem, solution.bullets.0)" },
              value: { description: "Nouvelle valeur (JSON)" }
            },
            required: ["path", "value"]
          }
        }
      },
      required: ["useCaseId", "updates"]
    }
  }
};

export interface SearchResult {
  title: string;
  url: string;
  content: string;
  score: number;
}

interface TavilySearchResponse {
  results?: SearchResult[];
}

interface TavilyExtractResponse {
  markdown?: string;
  content?: string;
}

export const searchWeb = async (query: string, signal?: AbortSignal): Promise<SearchResult[]> => {
  console.log(`üîç Tavily search called with query: "${query}"`);
  if (signal?.aborted) {
    throw new Error('AbortError');
  }
  const resp = await fetch("https://api.tavily.com/search", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${TAVILY_API_KEY}`
    },
    body: JSON.stringify({
      query,
      max_results: 10
    }),
    signal
  });
  
  const data = (await resp.json()) as TavilySearchResponse;
  console.log(`‚úÖ Tavily returned ${data.results?.length || 0} results`);
  return data.results || [];
}; 

export interface ExtractResult {
  url: string;
  content: string;   // markdown
}

export const extractUrlContent = async (
  url: string,
  signal?: AbortSignal
): Promise<ExtractResult> => {
  console.log(`üîç Tavily extract called with query: "${url}"`);

  if (signal?.aborted) throw new Error("AbortError");

  const resp = await fetch("https://api.tavily.com/extract", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${TAVILY_API_KEY}`
    },
    body: JSON.stringify({
      url,
      format: "markdown",      // "markdown" | "text"
      extract_depth: "advanced" // "basic" | "advanced"
    }),
    signal
  });

  const data = (await resp.json()) as TavilyExtractResponse;

  return {
    url,
    content: data.markdown ?? data.content ?? ""
  };
};


export interface ExecuteWithToolsOptions {
  model?: string;
  useWebSearch?: boolean;
  responseFormat?: 'json_object';
  signal?: AbortSignal;
}

export interface ExecuteWithToolsStreamOptions extends ExecuteWithToolsOptions {
  /**
   * ID du stream √† utiliser (si non fourni, g√©n√©r√© √† partir des champs ci-dessous).
   */
  streamId?: string;
  promptId?: string;
  jobId?: string;
  messageId?: string;
  /**
   * R√©sum√© de reasoning (Responses API). Default: auto
   */
  reasoningSummary?: 'auto' | 'concise' | 'detailed';
}

export interface ExecuteWithToolsStreamResult {
  streamId: string;
  content: string;
}

/**
 * Orchestrateur pour ex√©cuter des prompts avec ou sans outils
 */
export const executeWithTools = async (
  prompt: string, 
  options: ExecuteWithToolsOptions = {}
): Promise<OpenAI.Chat.Completions.ChatCompletion> => {
  const { model = 'gpt-4.1-nano', useWebSearch = false, responseFormat, signal } = options;

  console.log(`ü§ñ Using model: ${model}${useWebSearch ? ' with web search' : ''}`);

  if (!useWebSearch) {
    // Appel simple sans outils
    return await callOpenAI({
      messages: [
        {
          role: "user",
          content: prompt
        }
      ],
      model,
      responseFormat,
      signal
    });
  }

  // Appel avec recherche web et extraction d'URL
  // Premier appel pour d√©clencher la recherche et/ou l'extraction
  const response = await callOpenAI({
    messages: [
      {
        role: "system",
        content: WEB_TOOLS_SYSTEM_PROMPT
      },
      {
        role: "user",
        content: prompt
      }
    ],
    model,
    tools: [webSearchTool, webExtractTool],
    toolChoice: "required",
    responseFormat,
    signal
  });

  const message = response.choices[0]?.message;

  if (message?.tool_calls) {
    // Note: allSearchResults stocke les r√©sultats de recherche avec leur query associ√©e
    // Ce n'est pas le type SearchResult[], mais un tableau d'objets contenant query et results
    const allSearchResults: Array<{ query: string; results: SearchResult[] }> = [];
    const allExtractResults: ExtractResult[] = [];

    // Ex√©cuter toutes les recherches et extractions demand√©es
    for (const toolCall of message.tool_calls) {
      if (signal?.aborted) {
        throw new Error('AbortError');
      }
      if (toolCall.type === 'function') {
        if (toolCall.function.name === 'web_search') {
          const args = JSON.parse(toolCall.function.arguments);
          const searchResults = await searchWeb(args.query, signal);
          allSearchResults.push({
            query: args.query,
            results: searchResults
          });
        } else if (toolCall.function.name === 'web_extract') {
          const args = JSON.parse(toolCall.function.arguments);
          const urls = Array.isArray(args.urls) ? args.urls : [args.url || args.urls];
          // Extraire toutes les URLs en parall√®le
          const extractPromises = urls.map((url: string) => extractUrlContent(url, signal));
          const extractResults = await Promise.all(extractPromises);
          allExtractResults.push(...extractResults);
        }
      }
    }

    // Construire le message avec les r√©sultats
    let resultsMessage = '';
    if (allSearchResults.length > 0) {
      resultsMessage += `Voici les r√©sultats de recherche web:\n${JSON.stringify(allSearchResults, null, 2)}\n\n`;
    }
    if (allExtractResults.length > 0) {
      resultsMessage += `Voici les contenus extraits des URLs:\n${JSON.stringify(allExtractResults, null, 2)}\n\n`;
    }
    resultsMessage += WEB_TOOLS_RESULTS_SUFFIX;

    // Deuxi√®me appel avec les r√©sultats de recherche et d'extraction
    const followUpResponse = await callOpenAI({
      messages: [
        {
          role: "system",
          content: WEB_TOOLS_FOLLOWUP_SYSTEM_PROMPT
        },
        {
          role: "user",
          content: prompt
        },
        {
          role: "assistant",
          content: WEB_TOOLS_FOLLOWUP_ASSISTANT_PROMPT
        },
        {
          role: "user",
          content: resultsMessage
        }
      ],
      model,
      responseFormat,
      signal
    });

    return followUpResponse;
  }

  return response;
};

/**
 * Orchestrateur streaming √©quivalent √† executeWithTools
 * - R√©utilise EXACTEMENT les m√™mes prompts d'orchestration que la version non-streaming.
 * - √âcrit les √©v√©nements dans chat_stream_events via stream-service.
 */
export const executeWithToolsStream = async (
  prompt: string,
  options: ExecuteWithToolsStreamOptions = {}
): Promise<ExecuteWithToolsStreamResult> => {
  const {
    model = 'gpt-4.1-nano',
    useWebSearch = false,
    responseFormat,
    reasoningSummary,
    streamId,
    promptId,
    jobId,
    messageId,
    signal
  } = options;

  const finalStreamId = streamId || generateStreamId(promptId, jobId, messageId);

  // Helper: √©crire un StreamEvent normalis√©
  const write = async (eventType: StreamEventType, data: unknown) => {
    const seq = await getNextSequence(finalStreamId);
    await writeStreamEvent(finalStreamId, eventType, data, seq);
  };

  let accumulatedContent = '';

  if (!useWebSearch) {
    for await (const event of callOpenAIResponseStream({
      messages: [{ role: 'user', content: prompt }],
      model,
      responseFormat,
      reasoningSummary,
      signal
    })) {
      const data = (event.data ?? {}) as Record<string, unknown>;
      await write(event.type, data);
      if (event.type === 'content_delta') accumulatedContent += (typeof data.delta === 'string' ? data.delta : '');
      if (event.type === 'error') throw new Error(typeof data.message === 'string' ? data.message : 'Erreur lors du streaming');
    }
    return { streamId: finalStreamId, content: accumulatedContent };
  }

  // 1er appel (streaming) pour d√©clencher tools
  const toolCalls: Array<{ id: string; name: string; args: string }> = [];

  for await (const event of callOpenAIResponseStream({
    messages: [
      { role: 'system', content: WEB_TOOLS_SYSTEM_PROMPT },
      { role: 'user', content: prompt }
    ],
    model,
    tools: [webSearchTool, webExtractTool],
    responseFormat,
    reasoningSummary,
    signal
  })) {
    const data = (event.data ?? {}) as Record<string, unknown>;
    await write(event.type, data);

    if (event.type === 'content_delta') accumulatedContent += (typeof data.delta === 'string' ? data.delta : '');

    if (event.type === 'tool_call_start') {
      const toolCallId = typeof data.tool_call_id === 'string' ? data.tool_call_id : '';
      const existingIndex = toolCalls.findIndex(tc => tc.id === toolCallId);
      if (existingIndex === -1) {
        toolCalls.push({
          id: toolCallId,
          name: typeof data.name === 'string' ? data.name : '',
          args: typeof data.args === 'string' ? data.args : ''
        });
      } else {
        const nextName = typeof data.name === 'string' ? data.name : '';
        const nextArgs = typeof data.args === 'string' ? data.args : '';
        toolCalls[existingIndex].name = nextName || toolCalls[existingIndex].name;
        toolCalls[existingIndex].args = (toolCalls[existingIndex].args || '') + (nextArgs || '');
      }
    } else if (event.type === 'tool_call_delta') {
      const toolCallId = typeof data.tool_call_id === 'string' ? data.tool_call_id : '';
      const delta = typeof data.delta === 'string' ? data.delta : '';
      const toolCall = toolCalls.find(tc => tc.id === toolCallId);
      if (toolCall) {
        toolCall.args += delta;
      } else {
        toolCalls.push({ id: toolCallId, name: '', args: delta });
      }
    }

    if (event.type === 'error') throw new Error(typeof data.message === 'string' ? data.message : 'Erreur lors du streaming');
  }

  // Si aucun tool call: le contenu est d√©j√† complet
  if (toolCalls.length === 0) {
    return { streamId: finalStreamId, content: accumulatedContent };
  }

  // Ex√©cuter les tools (hors OpenAI) + streamer les r√©sultats via tool_call_result
  const allSearchResults: Array<{ query: string; results: SearchResult[] }> = [];
  const allExtractResults: ExtractResult[] = [];

  for (const toolCall of toolCalls) {
    if (signal?.aborted) throw new Error('AbortError');
    try {
      const args = JSON.parse(toolCall.args || '{}');
      if (toolCall.name === 'web_search') {
        await write('tool_call_result', { tool_call_id: toolCall.id, result: { status: 'executing' } });
        const searchResults = await searchWeb(args.query, signal);
        allSearchResults.push({ query: args.query, results: searchResults });
        await write('tool_call_result', { tool_call_id: toolCall.id, result: { status: 'completed', results: searchResults } });
      } else if (toolCall.name === 'web_extract') {
        await write('tool_call_result', { tool_call_id: toolCall.id, result: { status: 'executing' } });
        const urls = Array.isArray(args.urls) ? args.urls : [args.url || args.urls].filter(Boolean);
        const extractPromises = urls.map((url: string) => extractUrlContent(url, signal));
        const extractResults = await Promise.all(extractPromises);
        allExtractResults.push(...extractResults);
        await write('tool_call_result', { tool_call_id: toolCall.id, result: { status: 'completed', results: extractResults } });
      }
    } catch (error) {
      await write('tool_call_result', {
        tool_call_id: toolCall.id,
        result: { status: 'error', error: error instanceof Error ? error.message : 'Unknown error' }
      });
    }
  }

  // Construire resultsMessage (identique √† executeWithTools)
  let resultsMessage = '';
  if (allSearchResults.length > 0) {
    resultsMessage += `Voici les r√©sultats de recherche web:\n${JSON.stringify(allSearchResults, null, 2)}\n\n`;
  }
  if (allExtractResults.length > 0) {
    resultsMessage += `Voici les contenus extraits des URLs:\n${JSON.stringify(allExtractResults, null, 2)}\n\n`;
  }
  resultsMessage += WEB_TOOLS_RESULTS_SUFFIX;

  // 2e appel (streaming) avec les r√©sultats ‚Äî identique √† executeWithTools
  accumulatedContent = '';
  for await (const event of callOpenAIResponseStream({
    messages: [
      { role: 'system', content: WEB_TOOLS_FOLLOWUP_SYSTEM_PROMPT },
      { role: 'user', content: prompt },
      { role: 'assistant', content: WEB_TOOLS_FOLLOWUP_ASSISTANT_PROMPT },
      { role: 'user', content: resultsMessage }
    ],
    model,
    responseFormat,
    reasoningSummary,
    signal
  })) {
    const data = (event.data ?? {}) as Record<string, unknown>;
    await write(event.type, data);
    if (event.type === 'content_delta') accumulatedContent += (typeof data.delta === 'string' ? data.delta : '');
    if (event.type === 'error') throw new Error(typeof data.message === 'string' ? data.message : 'Erreur lors du streaming');
  }

  return { streamId: finalStreamId, content: accumulatedContent };
};
