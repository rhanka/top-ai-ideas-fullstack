# Feature: Lot A ‚Äî Mise √† jour cibl√©e d'un objet (Chatbot)

## Objective
Impl√©menter la fonctionnalit√© de base du chatbot permettant √† l'IA de proposer et d'appliquer une am√©lioration cibl√©e sur un use case existant avec reasoning en temps r√©el et tra√ßabilit√© compl√®te. Le parcours folder sera ajout√© ult√©rieurement.

**Valeur m√©tier** : D√©monstration client d√®s le premier incr√©ment. L'IA propose et applique une am√©lioration cibl√©e sur un objet m√©tier existant avec reasoning temps r√©el et tra√ßabilit√©.

**Port√©e fonctionnelle** : Mise √† jour de `use_cases.data.description` uniquement pour cette premi√®re it√©ration (le parcours folder sera ajout√© ult√©rieurement).

**Couverture CU** : CU-001, CU-003, CU-004 (minimal), CU-002 (basique), CU-010, CU-016

## Plan / Todo

### Phase 1 : Mod√®le de donn√©es et migrations ‚úÖ
- [x] Cr√©er les tables n√©cessaires dans le sch√©ma Drizzle :
  - [x] `chat_sessions` (sessions de chat utilisateur)
  - [x] `chat_messages` (messages de conversation avec reasoning)
  - [x] `chat_contexts` (liaison sessions ‚Üî objets m√©tier)
  - [x] `chat_stream_events` (√©v√©nements de streaming)
  - [x] `context_modification_history` (historique des modifications)
- [x] G√©n√©rer les migrations Drizzle (`make db-generate`) ‚Üí `0011_past_drax.sql`
- [x] Appliquer les migrations (`make db-migrate`)
- [x] V√©rifier le sch√©ma - toutes les tables cr√©√©es avec succ√®s

### Phase 2 : API Backend - Architecture streaming et chat

#### Phase 2A - Streaming complet pour g√©n√©ration d'entreprise (POC)
**Objectif** : Impl√©menter le streaming complet (OpenAI + DB + NOTIFY) sur un seul cas simple (entreprise) pour valider l'architecture avant g√©n√©ralisation.

**Flux actuel** :
- `POST /api/v1/companies/ai-enrich` ‚Üí appelle directement `enrichCompany` (sans queue)
- Queue `processCompanyEnrich` ‚Üí appelle `enrichCompany` puis met √† jour DB

**Flux cible** :
- M√™me comportement final (r√©sultat JSON pars√©, DB mise √† jour)
- **+ Streaming** : √©v√©nements √©crits dans `chat_stream_events` pendant l'ex√©cution
- **+ NOTIFY** : PostgreSQL NOTIFY pour temps r√©el
- **+ Queue compatible** : la queue attend toujours le r√©sultat final de `enrichCompany`

**T√¢ches** :
- [ ] **2A.1 - Couche OpenAI Streaming** :
  - Cr√©er `callOpenAIStream` dans `api/src/services/openai.ts` :
    - Retourne `AsyncIterable<StreamEvent>` o√π `StreamEvent` = `{ type: 'reasoning_delta' | 'content_delta' | 'tool_call_start' | 'tool_call_delta' | 'tool_call_result' | 'done', data: any }`
    - G√®re reasoning, content, tool_calls en streaming
    - Mutualise les valeurs par d√©faut du mod√®le (via `settingsService.getAISettings().defaultModel`)
    - Garde `callOpenAI` pour compatibilit√© (g√©n√©rations classiques actuelles)
  
- [ ] **2A.2 - Service Stream Partag√© (base)** :
  - Cr√©er `api/src/services/stream-service.ts` :
    - Fonction `writeStreamEvent(streamId, eventType, data, sequence)` :
      - √âcrit dans `chat_stream_events` (avec `message_id=null` pour g√©n√©rations classiques)
      - PostgreSQL NOTIFY avec payload minimal (`stream_id`, `sequence`)
      - Gestion des s√©quences (auto-incr√©ment par `stream_id`)
    - Fonction `generateStreamId(promptId?, jobId?)` : g√©n√®re `stream_id` unique
      - Pour g√©n√©rations classiques : `prompt_id` + timestamp (ou `job_id` si disponible)
      - Pour chat : `message_id` (sera utilis√© plus tard)
  
- [ ] **2A.3 - Adapter enrichCompany pour streaming** :
  - Modifier `api/src/services/context-company.ts` :
    - `enrichCompany` accepte un param√®tre optionnel `streamId?: string`
    - Utilise `callOpenAIStream` au lieu de `executeWithTools` ‚Üí `callOpenAI`
    - **Collecte le r√©sultat final** : agr√®ge tous les `content_delta` pour reconstruire le JSON complet
    - **√âcrit les √©v√©nements** : appelle `writeStreamEvent` pour chaque √©v√©nement de streaming
    - **Retourne le r√©sultat final** : parse le JSON comme avant (compatibilit√©)
    - G√®re les tool calls (web_search, web_extract) en streaming
  
- [ ] **2A.4 - Int√©gration queue** :
  - Modifier `queue-manager.ts` ‚Üí `processCompanyEnrich` :
    - G√©n√®re un `streamId` (ex: `company_enrich_${jobId}_${timestamp}`)
    - Passe le `streamId` √† `enrichCompany`
    - La queue attend toujours le r√©sultat final (comportement inchang√©)
    - Met √† jour la DB comme avant
  
- [ ] **2A.5 - Endpoint SSE pour g√©n√©rations classiques** (optionnel pour cette phase) :
  - Cr√©er `GET /api/v1/stream/:stream_id` (SSE) :
    - Lecture des √©v√©nements depuis `chat_stream_events`
    - Support du param√®tre `?since=seq` pour rehydratation
    - Abonnement PostgreSQL NOTIFY pour temps r√©el
  - **Note** : Cet endpoint servira aussi pour le chat plus tard

- [ ] **2A.6 - Tests et validation** :
  - Test unitaire : `callOpenAIStream` retourne bien un AsyncIterable
  - Test unitaire : `writeStreamEvent` √©crit bien en DB et NOTIFY
  - Test int√©gration : `enrichCompany` avec streaming retourne le m√™me r√©sultat qu'avant
  - Test int√©gration : √©v√©nements √©crits dans `chat_stream_events` avec `message_id=null`
  - Test queue : `processCompanyEnrich` fonctionne toujours (r√©sultat final + DB mise √† jour)
  - Test E2E : enrichissement d'entreprise fonctionne (endpoint `/ai-enrich` et via queue)

**Crit√®res de validation Phase 2A** :
- ‚úÖ Les g√©n√©rations d'entreprise fonctionnent toujours (comportement final identique)
- ‚úÖ Les √©v√©nements de streaming sont √©crits dans `chat_stream_events`
- ‚úÖ PostgreSQL NOTIFY fonctionne
- ‚úÖ La queue continue de fonctionner normalement
- ‚úÖ Un seul test UAT complet suffit

#### Phase 2B - G√©n√©ralisation aux autres g√©n√©rations classiques
- [x] Adapter `generateUseCaseList` pour utiliser le streaming
- [x] Adapter `generateUseCaseDetail` pour utiliser le streaming
- [x] Adapter `generateExecutiveSummary` pour utiliser le streaming
- [x] Tous utilisent le m√™me tronc commun (orchestrateur `executeWithToolsStream`) + persistance dans `chat_stream_events`
- [x] Int√©gration UI sur les vues dossiers / cas d'usage (SSE, sans polling)

#### Phase 2C - Service Chat
- [x] Cr√©er `api/src/services/chat-service.ts` :
  - Gestion des sessions (cr√©ation, r√©cup√©ration, mise √† jour)
  - Cr√©ation de messages (user et assistant)
  - Int√©gration avec streaming (via job `chat_message` en queue pour pr√©parer le scaling / workers d√©di√©s)
  - Utilisation du mod√®le par d√©faut depuis settings

#### Phase 2D - Endpoints Chat
- [x] Cr√©er le router `/api/v1/chat` dans `api/src/routes/api/chat.ts`
- [x] Impl√©menter `POST /api/v1/chat/messages` :
  - Cr√©ation de session si n√©cessaire
  - Enregistrement du message utilisateur
  - Enfile un job `chat_message` (pr√©pare le scaling / workers d√©di√©s)
  - Enregistrement du message assistant avec reasoning
- [x] Impl√©menter `GET /api/v1/chat/sessions` et `GET /api/v1/chat/sessions/:id/messages`
- [x] Option C (historique complet tools/reasoning) :
  - API : `GET /api/v1/chat/messages/:id/stream-events` (lecture `chat_stream_events`, `streamId = messageId`)
  - UI : rehydratation des √©tapes tools/reasoning des derniers messages assistant lors du chargement d'une session
  - Optimisation : endpoint batch `GET /api/v1/chat/sessions/:id/stream-events` (1 call/session au lieu de N calls/message)
- [x] **Streaming** : pas d'endpoint d√©di√© `GET /api/v1/chat/stream/:stream_id`.
  - Le client utilise le **SSE global** `GET /api/v1/streams/sse` et filtre par `streamId`
  - `streamId` du chat = `assistantMessageId` (retourn√© par `POST /chat/messages`)
- [x] Monter le router dans `api/src/routes/api/index.ts`
- [x] Mettre √† jour OpenAPI (`api/src/openapi/`) (minimal : endpoints chat)

#### Phase 2E - Tool Service
- [x] Cr√©er `api/src/services/tool-service.ts` :
  - Ex√©cution d'un tool **g√©n√©rique** `update_usecase_field` (usecase uniquement, champs `use_cases.data.*`)
  - Validation des modifications
  - √âcriture dans `context_modification_history`
  - Snapshots avant/apr√®s dans `chat_contexts`
  - Feature d'annulation du dernier changement au niveau de l'objet

### Phase 3 : UI SvelteKit - Composants de base
- [x] **Unifier le widget flottant global (1 seule bulle)** :
  - Cr√©er `ui/src/lib/components/ChatWidget.svelte`
    - Contient **la bulle** (bouton fixed) + **le panneau** (drawer)
    - Header avec switch de vue: **Chat** ‚Üî **QueueMonitor**
    - La bulle refl√®te un √©tat global (jobs en cours/failed + conversations en cours/erreurs)
  - Remplacer l‚Äôinjection de `QueueMonitor` dans `ui/src/routes/+layout.svelte` par ce widget unique
- [x] **Ergonomie de la bulle & du panneau (it√©rations)** :
  - Bulle = **ic√¥ne chat** (toujours visible), avec **badge montre** si jobs IA actifs (`pending/processing`)
  - Le statut ‚Äúmontre‚Äù se **r√©initialise** automatiquement d√®s qu‚Äôil n‚Äôy a plus de jobs actifs (fin/purge)
  - Fen√™tre plus haute (**~70vh**), ancr√©e en bas √† droite, et **recouvre** l‚Äôemplacement de la bulle (bulle cach√©e pendant l‚Äôouverture)
  - Fix layout: wrapper en `flex flex-col` + content `flex-1 min-h-0` pour conserver le composer visible en bas
  - Optimisation perf: le panneau est **mont√© une seule fois**, puis on fait **hide/show** (pas de remount ‚Üí pas d‚Äôappels API √† chaque ouverture/fermeture)
  - Optimisation perf: switch **Jobs IA ‚Üî Chat** en hide/show (ChatPanel + QueueMonitor restent mont√©s)
  - Anti-reload: retour depuis ‚ÄúJobs IA‚Äù vers **la m√™me session** ne relance pas `selectSession()` (√©vite ‚ÄúChargement du d√©tail‚Ä¶‚Äù)
  - Nettoyage: suppression de `StreamMessageLegacy.svelte` (plus de variant legacy, `StreamMessage` couvre chat + job)
  - UI: scrollbar **uniformis√©e** (classe globale `.slim-scroll`) sur ChatPanel + Jobs IA + zones de d√©tail StreamMessage
  - Fix r√©activit√©: cl√© composite dans `{#each}` de QueueMonitor (`${job.id}-${job.status}-${job.completedAt || ''}`) pour forcer la mise √† jour de l'UI quand le status change (Svelte recr√©e les blocs DOM)
  - Fix UX: correction de `showDetailLoader` dans StreamMessage pour exclure les jobs (√©vite d'afficher "Chargement du d√©tail..." pour les jobs pending)
- [x] **QueueMonitor r√©utilis√© comme panel** (sans requalifier) :
  - `QueueMonitor` conserve le contenu existant, mais **sans bulle/wrapper fixed/header**
  - Le titre et le bouton poubelle sont d√©plac√©s dans le header du widget
- [x] **UI Chat (vue dans le widget)** :
  - [x] `ChatPanel.svelte` : liste sessions + messages + composer (envoi `POST /chat/messages`)
  - [x] Streaming c√¥t√© UI : r√©sum√© en gris (dur√©e + nb d'outils) + chevron + d√©tail (raisonnement/outils sans r√©sultat), stream du r√©sultat dans la bulle, puis refresh messages au `done/error` (**scroll coll√© en bas**)
  - [x] UX: d√®s `status: started`, afficher un loader "En cours‚Ä¶" dans la zone grise (avant reasoning/outils/r√©ponse)
  - [x] D√©placer la s√©lection de session dans le header du widget (`ChatWidget`) + actions **+** (nouvelle session locale) et **üóëÔ∏è** (supprimer conversation)
  - [x] API : `DELETE /api/v1/chat/sessions/:id` (cascade DB)
  - Streaming: r√©utiliser `streamHub` + `StreamMessage` (pas de 2·µâ composant de rendu)
    - `streamId` = `assistantMessageId`
    - `StreamMessage` est la brique unique pour afficher l‚Äôavancement (reasoning/tools/content) + historique
- [x] **Data fetch (non-streaming)** :
  - `GET /chat/sessions` + `GET /chat/sessions/:id/messages` pour recharger l'historique apr√®s refresh
  - SSE global `/streams/sse` seulement pour les messages en cours / nouveaux events (cache/replay = confort UX)
- [x] **Chat global (pas page-scoped)** :
  - Le chat est disponible **partout** (ChatWidget disponible via `+layout.svelte`)
  - Le contexte est automatiquement d√©tect√© depuis l'URL (route + id le cas √©ch√©ant), pas besoin de s√©lecteur UI d√©di√©
  - Le diff (Avant/Apr√®s) sera impl√©ment√© dans le Lot D

#### Convergence StreamMessage (Chat vs Jobs) ‚Äî analyse de r√©trofit
- **Constat** :
  - Le `ChatPanel` a aujourd'hui **l'ergonomie cible** (zone grise steps, r√©sum√© ‚ÄúRaisonnement X, N outils‚Äù, chevron + d√©tail).
  - `StreamMessage.svelte` existe d√©j√†, mais il est plut√¥t ‚Äújob progress compact‚Äù (√©tape + historique), et ne porte pas l'UX Chat.
- **Diff√©rences r√©elles Chat vs Job (faibles)** :
  - **Chat**: rendu du **r√©sultat** dans une bulle + remplacement par le contenu final quand `done`.
  - **Jobs**: pas de bulle de r√©ponse (ou pas toujours), mais on veut **la m√™me lecture** des steps (reasoning/tools) + historique.
  - **Hydratation historique**:
    - Chat: scopes user/session (endpoints `/chat/*`).
    - Jobs: scope ‚ÄústreamId‚Äù (ex: `job_<id>`, `company_<id>`), n√©cessite un endpoint g√©n√©rique `/streams/*`.
- **Plan (5 √©tapes)** :
  - [x] (1) Documenter cette convergence (section actuelle).
  - [x] (2) Remplacer `StreamMessage` par une version unifi√©e qui reprend l'UX du chat (backup: `StreamMessageLegacy.svelte`).
  - [x] (3) API: permettre la relecture d'historique par `streamId` (jobs inclus) avec `limit/since` (`GET /api/v1/streams/events/:streamId`).
  - [x] (4) Adapter `StreamMessage` au besoin QueueMonitor (variant `job`: steps + historique, sans bulle chat).
  - [x] (5) Adapter `QueueMonitor` pour utiliser `StreamMessage` (live SSE + historique API via `historySource="stream"`).

### Phase 4 : Int√©gration tool call dans le chat
- [x] **4.1 - UI : D√©tection automatique du contexte depuis la route** :
  - Dans `ChatPanel.svelte`, d√©tecter la route actuelle via `$page.route.id` et `$page.params`
  - Mapper les routes aux contextes :
    - `/cas-usage/[id]` ‚Üí `primaryContextType: 'usecase'`, `primaryContextId: $page.params.id`
    - `/dossiers/[id]` ‚Üí `primaryContextType: 'folder'`, `primaryContextId: $page.params.id`
    - `/entreprises/[id]` ‚Üí `primaryContextType: 'company'`, `primaryContextId: $page.params.id`
  - Modifier `sendMessage()` pour inclure `primaryContextType` et `primaryContextId` dans l'appel `POST /chat/messages`
  - G√©rer le cas o√π on n'est pas sur une route avec contexte (pas de tool disponible)
- [ ] **4.2 - API : Passage des tools √† OpenAI** :
  - [x] **4.2.1 - Cr√©er le tool `read_usecase`** :
    - Cr√©er `readUseCaseTool` dans `tools.ts` (param√®tre `useCaseId`, retourne le use case complet)
    - Cr√©er `readUseCase()` dans `tool-service.ts` pour lire le use case depuis la DB
    - Retourner la structure `use_cases.data` compl√®te
  - [x] **4.2.2 - Passer les tools √† OpenAI** :
    - Dans `chat-service.ts` ‚Üí `runAssistantGeneration()`, r√©cup√©rer le contexte depuis la session (`primaryContextType`, `primaryContextId`)
    - Importer `readUseCaseTool`, `updateUseCaseFieldTool`, `webSearchTool` et `webExtractTool` depuis `tools.ts`
    - Conditionner le passage des tools : ne passer `tools: [readUseCaseTool, updateUseCaseFieldTool, webSearchTool, webExtractTool]` que si `primaryContextType === 'usecase'`
    - Passer les tools √† `callOpenAIResponseStream()` dans les options
    - Enrichir le system prompt avec le contexte usecase pour guider l'IA
  - [x] **4.2.3 - Int√©gration des tools web (web_search, web_extract)** :
    - `web_search` : Recherche d'informations r√©centes sur le web pour trouver de nouvelles URLs ou obtenir des r√©sum√©s
    - `web_extract` : Extraction du contenu complet d'une ou plusieurs URLs existantes (r√©f√©rences du use case)
    - Correction du parsing de la r√©ponse Tavily : utiliser `raw_content` au lieu de `markdown`/`content` dans la structure `results[]`
    - Support de l'appel group√© : `web_extract` accepte un array d'URLs pour extraire plusieurs URLs en un seul appel
    - Workflow guid√© dans le system prompt : lire le use case ‚Üí extraire les URLs depuis `data.references` ‚Üí appeler `web_extract` une seule fois avec toutes les URLs
- [x] **4.3 - API : Gestion des tool calls dans le stream** :
  - Dans `runAssistantGeneration()`, g√©rer les √©v√©nements `tool_call_start`, `tool_call_delta`, `done`
  - Pour `tool_call_start` : initialiser un objet pour stocker les arguments du tool call
  - Pour `tool_call_delta` : accumuler les arguments JSON (comme pour `content_delta`)
  - Boucle it√©rative pour g√©rer plusieurs rounds de tool calls (max 10 it√©rations)
  - Collecter tous les tool calls avant de les ex√©cuter
- [x] **4.4 - API : Ex√©cution des tools** :
  - Apr√®s avoir collect√© tous les tool calls dans un round, ex√©cuter chaque tool :
    - **Pour `read_usecase`** :
      - Parser les arguments accumul√©s (`useCaseId`)
      - V√©rifier que `useCaseId` correspond au `primaryContextId` de la session (s√©curit√©)
      - Appeler `toolService.readUseCase()` avec `useCaseId`
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'` avec le use case complet)
    - **Pour `update_usecase_field`** :
      - Parser les arguments accumul√©s (`useCaseId`, `updates`)
      - V√©rifier que `useCaseId` correspond au `primaryContextId` de la session (s√©curit√©)
      - Appeler `toolService.updateUseCaseFields()` avec :
        - `useCaseId` depuis les arguments
        - `updates` depuis les arguments
        - `sessionId` et `assistantMessageId` pour l'historique
        - `toolCallId` pour la tra√ßabilit√©
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
    - **Pour `web_search`** :
      - Parser les arguments accumul√©s (`query`)
      - Appeler `searchWeb()` depuis `tools.ts` (API Tavily)
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream avec les r√©sultats de recherche
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
    - **Pour `web_extract`** :
      - Parser les arguments accumul√©s (`urls` - array d'URLs)
      - Appeler `extractUrlContent()` pour chaque URL (en parall√®le via `Promise.all`)
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream avec les contenus extraits
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
  - Ajouter tous les r√©sultats des tools √† la conversation pour continuer le stream dans le round suivant
- [x] **4.5 - API : Transmission du contexte au mod√®le** :
  - Enrichir le `systemPrompt` dans `runAssistantGeneration()` pour inclure le contexte :
    - Si `primaryContextType === 'usecase'` : "Tu travailles sur le use case {primaryContextId}. Tu peux utiliser le tool `read_usecase` pour lire son √©tat actuel, puis `update_usecase_field` pour modifier ses champs."
    - Ajout des tools web : `web_search` pour rechercher de nouvelles informations, `web_extract` pour extraire le contenu des r√©f√©rences existantes
    - Workflow guid√© pour l'analyse des r√©f√©rences : lire le use case ‚Üí extraire URLs depuis `data.references` ‚Üí appeler `web_extract` une seule fois avec toutes les URLs
    - Instructions explicites pour regrouper les URLs dans un seul appel `web_extract` (√©vite les appels multiples)
  - Alternative : inclure le contexte dans les messages de conversation (moins recommand√©)

- [x] **4.6 - Tests et validation** :
  - Test manuel : sur `/cas-usage/[id]`, demander une modification du use case et v√©rifier que le tool est appel√©
  - V√©rifier que les modifications sont bien √©crites en DB (`use_cases.data`)
  - V√©rifier que l'historique est cr√©√© (`context_modification_history`, `chat_contexts`)
  - V√©rifier que le mod√®le continue la conversation apr√®s l'ex√©cution du tool

**Crit√®res de validation Phase 4** :
- ‚úÖ Le contexte est automatiquement d√©tect√© depuis la route
- ‚úÖ Le tool est pass√© √† OpenAI uniquement quand le contexte est `usecase`
- ‚úÖ Les tool calls sont g√©r√©s dans le stream
- ‚úÖ Le tool est ex√©cut√© et les modifications sont appliqu√©es en DB
- ‚úÖ Le mod√®le continue la conversation apr√®s l'ex√©cution du tool
- ‚úÖ L'historique des modifications est trac√©

### Phase 5 : Tests
- [ ] Tests unitaires API :
  - Agr√©gation SSE (deltas reasoning/content)
  - Application de deltas
- Tool-call `update_usecase_field`
  - Validation des modifications
- [ ] Tests d'int√©gration API :
  - POST message ‚Üí SSE ‚Üí update description ‚Üí lecture DB
  - V√©rification `context_modification_history`
  - V√©rification snapshots dans `chat_contexts`
- [ ] Tests E2E Playwright :
  - Parcours "demande d'am√©lioration" sur un use case puis annulation
  - V√©rification description mise √† jour
  - V√©rification historique visible
  - Test de l'annulation du dernier changement

### Phase 6 : UndoBar (apr√®s validation des tests)
- [ ] **UndoBar** :
  - Bouton "Annuler" + preview de la derni√®re modification (via `context_modification_history` + `chat_contexts`)
  - Option: confirmation humaine pour actions ‚ö†Ô∏è
  - **Note** : √Ä impl√©menter apr√®s validation compl√®te des tests (Phase 5) pour garantir la stabilit√© de l'annulation

### Phase 7 : Documentation et finalisation
- [ ] Mettre √† jour la documentation OpenAPI
- [ ] V√©rifier que tous les tests passent (`make test`)
- [ ] V√©rifier le build (`make build`)
- [ ] Ex√©cuter les tests E2E (`make test-e2e`)
- [ ] V√©rifier CI GitHub Actions

## D√©cisions techniques

- **Parcours impl√©ment√©** : Use case uniquement (folder sera ajout√© ult√©rieurement)
- **Mod√®le OpenAI** : `gpt-4.1-nano` par d√©faut, r√©cup√©r√© via `settingsService.getAISettings().defaultModel`
- **Interface utilisateur** : Popup flottant similaire √† `QueueMonitor.svelte`, avec la queue en accord√©on dans le m√™me conteneur
- **Validation** : Pas de confirmation interm√©diaire. Feature d'annulation du dernier changement au niveau de l'objet (√† terme √† la maille du sous-objet `data.description`)

## Architecture & Incoh√©rences identifi√©es avec le plan initial

### Incoh√©rences identifi√©es

1. **Phase 2 vs Phase 3** : Le plan initial met "Service de streaming" en Phase 3, mais la couche streaming doit √™tre pr√™te AVANT les endpoints chat (Phase 2), car ils en d√©pendent.

2. **Queue pour chat** : le plan initial disait "direct sans queue", mais on a choisi un job `chat_message` pour pr√©parer le scaling (workers d√©di√©s). Le streaming reste en temps r√©el via `chat_stream_events` + SSE global.

3. **Architecture streaming** : Il faut une **couche streaming partag√©e** qui sert :
   - Les g√©n√©rations classiques (via queue) - qui deviendront plus transparentes pour tools/r√©flexion
   - Le chat (via queue `chat_message`, scalable)
   - M√©thodes partag√©es pour √©viter la duplication

### Approche progressive valid√©e

**Phase 2A - POC sur g√©n√©ration d'entreprise** :
- Cas le plus simple (pas de tool calls complexes, pas de multi-√©tapes)
- Permet de valider l'architecture compl√®te (streaming + DB + NOTIFY + queue)
- **Un seul test UAT complet** suffit avant g√©n√©ralisation
- G√©n√©ralisation ensuite (Phase 2B) aux autres g√©n√©rations classiques

**Gestion de la queue** :
- La queue continue de fonctionner normalement
- Elle attend toujours le r√©sultat final de `enrichCompany` (comportement inchang√©)
- Le streaming est transparent : √©v√©nements √©crits pendant l'ex√©cution, r√©sultat final collect√© et retourn√©

**R√©cup√©ration du r√©sultat final** :
- `enrichCompany` agr√®ge tous les `content_delta` pour reconstruire le JSON complet
- Parse le JSON comme avant (compatibilit√© totale)
- Retourne le r√©sultat final (comme avant)
- La queue met √† jour la DB avec ce r√©sultat (comportement inchang√©)

## Commits & Progress

- [x] **Phase 1** : Ajout des tables chat dans le sch√©ma Drizzle
  - Tables cr√©√©es : `chat_sessions`, `chat_messages`, `chat_contexts`, `chat_stream_events`, `context_modification_history`
  - Migration g√©n√©r√©e : `0011_past_drax.sql`
  - Migration appliqu√©e avec succ√®s
  - V√©rification : toutes les tables pr√©sentes en base

- [x] **Phase 2A (POC streaming entreprise + UI monitoring)** : Streaming end-to-end + affichage temps r√©el
  - **API**
    - SSE global : `GET /api/v1/streams/sse` (flux unique) + `LISTEN/NOTIFY` (`stream_events`, `job_events`, `company_events`)
    - `generateStreamId` d√©terministe pour jobs (`job_<jobId>`) + **enrich entreprise streamId** : `company_<companyId>`
    - `NOTIFY job_events` (queue) + `NOTIFY company_events` (CRUD + transitions de statut)
    - Typage ‚Äúsafe‚Äù sur `executeWithToolsStream` (`event.data` = `unknown`) pour √©viter les r√©gressions TS/ESLint
    - Compat OpenAI : d√©sactivation de `reasoning.summary` pour les mod√®les `gpt-4.1-*` (ex: `gpt-4.1-nano-*`) pour √©viter un 400
  - **UI**
    - Nouveau composant `StreamMessage` (prop `streamId`) : derni√®re √©tape + historique d√©pliable, deltas cumul√©s, auto-scroll bas, placeholder sans waiter
    - `streamHub` : connexion SSE unique + abonnements cibl√©s (`setStream`, `setJobUpdates`) + cache/replay + agr√©gation des deltas
    - `QueueMonitor` : bouton toujours √† jour (job_update m√™me repli√©) + suivi de stream via `StreamMessage`
    - Liste entreprises : remplacement du waiter en mode `enriching` par `StreamMessage` sur `company_<id>`
    - Raffinements `StreamMessage` : chevron sur la ligne du titre + scrollbar discr√®te (zones scrollables)

- [x] **Phase 2A.1** : Couche OpenAI Streaming
  - Cr√©√© `callOpenAIStream` dans `openai.ts`
  - Retourne `AsyncIterable<StreamEvent>`
  - G√®re content_delta, tool_call_start, tool_call_delta, status, error, done
  - Mutualise les valeurs par d√©faut du mod√®le via `settingsService.getAISettings().defaultModel`

- [x] **Phase 2A.2** : Service Stream Partag√©
  - Cr√©√© `stream-service.ts` avec `writeStreamEvent`, `generateStreamId`, `getNextSequence`, `readStreamEvents`
  - √âcriture dans `chat_stream_events` avec `message_id=null` pour g√©n√©rations classiques
  - PostgreSQL NOTIFY pour temps r√©el (payload minimal)

- [x] **Phase 2A.3** : Adapter enrichCompany pour streaming
  - Cr√©√© `enrichCompanyStream` qui utilise `callOpenAIStream`
  - Collecte le r√©sultat final (agr√®ge content_delta)
  - G√®re les tool calls (web_search, web_extract) en streaming
  - √âcrit tous les √©v√©nements dans `chat_stream_events`
  - `enrichCompany` accepte maintenant `streamId?` optionnel

- [x] **Phase 2A.4** : Int√©gration queue
  - Modifi√© `processCompanyEnrich` pour g√©n√©rer un `streamId` et le passer √† `enrichCompany`
  - La queue attend toujours le r√©sultat final (comportement inchang√©)

- [x] **Phase 2B (streaming dossiers + cas d'usage + synth√®se)** : G√©n√©ralisation aux g√©n√©rations classiques
  - **API**
    - Jobs : `use_case_list`, `use_case_detail`, `executive_summary` passent par `executeWithToolsStream`
    - `streamId` d√©terministes par entit√© : `folder_<folderId>`, `usecase_<useCaseId>`
    - √âv√©nements temps r√©el : `NOTIFY folder_events/usecase_events` + SSE `folder_update/usecase_update`
  - **UI**
    - Vues `/dossiers` et `/cas-usage` (liste + d√©tail) : suivi via SSE + `StreamMessage` (plus de polling)
    - Ergonomie cartes : suppression des badges jaunes ‚ÄúG√©n√©ration‚Ä¶‚Äù, `StreamMessage` plac√© aux bons endroits
    - Dossiers : masque le compteur ‚Äú0 cas d‚Äôusage‚Äù pendant la g√©n√©ration, et ‚ÄúS√©lectionn√©‚Äù affich√© dans le footer (pas dans le corps)

## Status
- **Progress**: Phase 1 + Phase 2A (POC entreprise) + Phase 2B + Phase 2E (Tool Service d√©fini) + Phase 3 (Widget global Chat/Queue + UI chat) ‚úÖ
- **Current**: Phase 4 - Int√©gration tool call dans le chat
- **Next**:
  - UI : D√©tection automatique du contexte depuis la route (Phase 4.1)
  - API : Passage du tool √† OpenAI et gestion des tool calls (Phase 4.2-4.5)
  - Tests : Phase 5 (unitaires, int√©gration, E2E)
  - UndoBar : Phase 6 (apr√®s validation des tests)
  - Documentation : Phase 7

## Scope
- **API** : Nouveaux endpoints chat, streaming SSE, tools
- **UI** : Nouveaux composants chat-stream, int√©gration dans vues existantes
- **DB** : Nouvelles tables pour chat, streaming, historique
- **Tests** : Unit, int√©gration, E2E pour le parcours complet
- **CI** : V√©rification que les tests passent dans GitHub Actions

## R√©f√©rences
- Sp√©cification compl√®te : `spec/SPEC_CHATBOT.md`
- Lot A d√©taill√© : `spec/SPEC_CHATBOT.md` lignes 800-818
- Mod√®le de donn√©es : `spec/SPEC_CHATBOT.md` lignes 228-426
- Architecture streaming : `spec/SPEC_CHATBOT.md` lignes 119-138
- Composants UI : `spec/SPEC_CHATBOT.md` lignes 146-203
