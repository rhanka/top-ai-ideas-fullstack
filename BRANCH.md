# Feature: Lot A ‚Äî Mise √† jour cibl√©e d'un objet (Chatbot)

> **R√©f√©rence** : Sp√©cification compl√®te dans `spec/SPEC_CHATBOT.md` (source de v√©rit√©). Ce document (`BRANCH.md`) suit l'impl√©mentation du Lot A.

## Objective
Impl√©menter la fonctionnalit√© de base du chatbot permettant √† l'IA de proposer et d'appliquer une am√©lioration cibl√©e sur un use case existant avec reasoning en temps r√©el et tra√ßabilit√© compl√®te. Le parcours folder sera ajout√© ult√©rieurement.

**Valeur m√©tier** : D√©monstration client d√®s le premier incr√©ment. L'IA propose et applique une am√©lioration cibl√©e sur un objet m√©tier existant avec reasoning temps r√©el et tra√ßabilit√©.

**Port√©e fonctionnelle** : Mise √† jour de `use_cases.data.*` via tool `update_usecase_field` (use case uniquement). Extension aux autres objets (folder, company, executive_summary) pr√©vue dans les Lots suivants.

**Couverture CU** : CU-001 (use case), CU-002 (partiel), CU-003, CU-004, CU-005 (use case), CU-010 (partiel), CU-015 (partiel), CU-016 (partiel), CU-019 (partiel), CU-020 (partiel), CU-021 (partiel)

## Plan / Todo

### Phase 1 : Mod√®le de donn√©es et migrations ‚úÖ
- [x] Cr√©er les tables n√©cessaires dans le sch√©ma Drizzle :
  - [x] `chat_sessions` (sessions de chat utilisateur)
  - [x] `chat_messages` (messages de conversation avec reasoning)
  - [x] `chat_contexts` (liaison sessions ‚Üî objets m√©tier)
  - [x] `chat_stream_events` (√©v√©nements de streaming)
  - [x] `context_modification_history` (historique des modifications)
- [x] G√©n√©rer les migrations Drizzle (`make db-generate`) ‚Üí `0011_past_drax.sql`
- [x] Appliquer les migrations (`make db-migrate`)
- [x] V√©rifier le sch√©ma - toutes les tables cr√©√©es avec succ√®s

### Phase 2 : API Backend - Architecture streaming et chat

#### Phase 2A - Streaming complet pour g√©n√©ration d'entreprise (POC)
**Objectif** : Impl√©menter le streaming complet (OpenAI + DB + NOTIFY) sur un seul cas simple (entreprise) pour valider l'architecture avant g√©n√©ralisation.

**Flux actuel** :
- `POST /api/v1/companies/ai-enrich` ‚Üí appelle directement `enrichCompany` (sans queue)
- Queue `processCompanyEnrich` ‚Üí appelle `enrichCompany` puis met √† jour DB

**Flux cible** :
- M√™me comportement final (r√©sultat JSON pars√©, DB mise √† jour)
- **+ Streaming** : √©v√©nements √©crits dans `chat_stream_events` pendant l'ex√©cution
- **+ NOTIFY** : PostgreSQL NOTIFY pour temps r√©el
- **+ Queue compatible** : la queue attend toujours le r√©sultat final de `enrichCompany`

**T√¢ches** :
- [ ] **2A.1 - Couche OpenAI Streaming** :
  - Cr√©er `callOpenAIStream` dans `api/src/services/openai.ts` :
    - Retourne `AsyncIterable<StreamEvent>` o√π `StreamEvent` = `{ type: 'reasoning_delta' | 'content_delta' | 'tool_call_start' | 'tool_call_delta' | 'tool_call_result' | 'done', data: any }`
    - G√®re reasoning, content, tool_calls en streaming
    - Mutualise les valeurs par d√©faut du mod√®le (via `settingsService.getAISettings().defaultModel`)
    - Garde `callOpenAI` pour compatibilit√© (g√©n√©rations classiques actuelles)
  
- [ ] **2A.2 - Service Stream Partag√© (base)** :
  - Cr√©er `api/src/services/stream-service.ts` :
    - Fonction `writeStreamEvent(streamId, eventType, data, sequence)` :
      - √âcrit dans `chat_stream_events` (avec `message_id=null` pour g√©n√©rations classiques)
      - PostgreSQL NOTIFY avec payload minimal (`stream_id`, `sequence`)
      - Gestion des s√©quences (auto-incr√©ment par `stream_id`)
    - Fonction `generateStreamId(promptId?, jobId?)` : g√©n√®re `stream_id` unique
      - Pour g√©n√©rations classiques : `prompt_id` + timestamp (ou `job_id` si disponible)
      - Pour chat : `message_id` (sera utilis√© plus tard)
  
- [ ] **2A.3 - Adapter enrichCompany pour streaming** :
  - Modifier `api/src/services/context-company.ts` :
    - `enrichCompany` accepte un param√®tre optionnel `streamId?: string`
    - Utilise `callOpenAIStream` au lieu de `executeWithTools` ‚Üí `callOpenAI`
    - **Collecte le r√©sultat final** : agr√®ge tous les `content_delta` pour reconstruire le JSON complet
    - **√âcrit les √©v√©nements** : appelle `writeStreamEvent` pour chaque √©v√©nement de streaming
    - **Retourne le r√©sultat final** : parse le JSON comme avant (compatibilit√©)
    - G√®re les tool calls (web_search, web_extract) en streaming
  
- [ ] **2A.4 - Int√©gration queue** :
  - Modifier `queue-manager.ts` ‚Üí `processCompanyEnrich` :
    - G√©n√®re un `streamId` (ex: `company_enrich_${jobId}_${timestamp}`)
    - Passe le `streamId` √† `enrichCompany`
    - La queue attend toujours le r√©sultat final (comportement inchang√©)
    - Met √† jour la DB comme avant
  
- [ ] **2A.5 - Endpoint SSE pour g√©n√©rations classiques** (optionnel pour cette phase) :
  - Cr√©er `GET /api/v1/stream/:stream_id` (SSE) :
    - Lecture des √©v√©nements depuis `chat_stream_events`
    - Support du param√®tre `?since=seq` pour rehydratation
    - Abonnement PostgreSQL NOTIFY pour temps r√©el
  - **Note** : Cet endpoint servira aussi pour le chat plus tard

- [ ] **2A.6 - Tests et validation** :
  - Test unitaire : `callOpenAIStream` retourne bien un AsyncIterable
  - Test unitaire : `writeStreamEvent` √©crit bien en DB et NOTIFY
  - Test int√©gration : `enrichCompany` avec streaming retourne le m√™me r√©sultat qu'avant
  - Test int√©gration : √©v√©nements √©crits dans `chat_stream_events` avec `message_id=null`
  - Test queue : `processCompanyEnrich` fonctionne toujours (r√©sultat final + DB mise √† jour)
  - Test E2E : enrichissement d'entreprise fonctionne (endpoint `/ai-enrich` et via queue)

**Crit√®res de validation Phase 2A** :
- ‚úÖ Les g√©n√©rations d'entreprise fonctionnent toujours (comportement final identique)
- ‚úÖ Les √©v√©nements de streaming sont √©crits dans `chat_stream_events`
- ‚úÖ PostgreSQL NOTIFY fonctionne
- ‚úÖ La queue continue de fonctionner normalement
- ‚úÖ Un seul test UAT complet suffit

#### Phase 2B - G√©n√©ralisation aux autres g√©n√©rations classiques
- [x] Adapter `generateUseCaseList` pour utiliser le streaming
- [x] Adapter `generateUseCaseDetail` pour utiliser le streaming
- [x] Adapter `generateExecutiveSummary` pour utiliser le streaming
- [x] Tous utilisent le m√™me tronc commun (orchestrateur `executeWithToolsStream`) + persistance dans `chat_stream_events`
- [x] Int√©gration UI sur les vues dossiers / cas d'usage (SSE, sans polling)

#### Phase 2C - Service Chat
- [x] Cr√©er `api/src/services/chat-service.ts` :
  - Gestion des sessions (cr√©ation, r√©cup√©ration, mise √† jour)
  - Cr√©ation de messages (user et assistant)
  - Int√©gration avec streaming (via job `chat_message` en queue pour pr√©parer le scaling / workers d√©di√©s)
  - Utilisation du mod√®le par d√©faut depuis settings

#### Phase 2D - Endpoints Chat
- [x] Cr√©er le router `/api/v1/chat` dans `api/src/routes/api/chat.ts`
- [x] Impl√©menter `POST /api/v1/chat/messages` :
  - Cr√©ation de session si n√©cessaire
  - Enregistrement du message utilisateur
  - Enfile un job `chat_message` (pr√©pare le scaling / workers d√©di√©s)
  - Enregistrement du message assistant avec reasoning
- [x] Impl√©menter `GET /api/v1/chat/sessions` et `GET /api/v1/chat/sessions/:id/messages`
- [x] Option C (historique complet tools/reasoning) :
  - API : `GET /api/v1/chat/messages/:id/stream-events` (lecture `chat_stream_events`, `streamId = messageId`)
  - UI : rehydratation des √©tapes tools/reasoning des derniers messages assistant lors du chargement d'une session
  - Optimisation : endpoint batch `GET /api/v1/chat/sessions/:id/stream-events` (1 call/session au lieu de N calls/message)
- [x] **Streaming** : pas d'endpoint d√©di√© `GET /api/v1/chat/stream/:stream_id`.
  - Le client utilise le **SSE global** `GET /api/v1/streams/sse` et filtre par `streamId`
  - `streamId` du chat = `assistantMessageId` (retourn√© par `POST /chat/messages`)
- [x] Monter le router dans `api/src/routes/api/index.ts`
- [x] Mettre √† jour OpenAPI (`api/src/openapi/`) (minimal : endpoints chat)

#### Phase 2E - Tool Service
- [x] Cr√©er `api/src/services/tool-service.ts` :
  - Ex√©cution d'un tool **g√©n√©rique** `update_usecase_field` (usecase uniquement, champs `use_cases.data.*`)
  - Validation des modifications
  - √âcriture dans `context_modification_history`
  - Snapshots avant/apr√®s dans `chat_contexts`
  - Feature d'annulation du dernier changement au niveau de l'objet

### Phase 3 : UI SvelteKit - Composants de base
- [x] **Unifier le widget flottant global (1 seule bulle)** :
  - Cr√©er `ui/src/lib/components/ChatWidget.svelte`
    - Contient **la bulle** (bouton fixed) + **le panneau** (drawer)
    - Header avec switch de vue: **Chat** ‚Üî **QueueMonitor**
    - La bulle refl√®te un √©tat global (jobs en cours/failed + conversations en cours/erreurs)
  - Remplacer l‚Äôinjection de `QueueMonitor` dans `ui/src/routes/+layout.svelte` par ce widget unique
- [x] **Ergonomie de la bulle & du panneau (it√©rations)** :
  - Bulle = **ic√¥ne chat** (toujours visible), avec **badge montre** si jobs IA actifs (`pending/processing`)
  - Le statut ‚Äúmontre‚Äù se **r√©initialise** automatiquement d√®s qu‚Äôil n‚Äôy a plus de jobs actifs (fin/purge)
  - Fen√™tre plus haute (**~70vh**), ancr√©e en bas √† droite, et **recouvre** l‚Äôemplacement de la bulle (bulle cach√©e pendant l‚Äôouverture)
  - Fix layout: wrapper en `flex flex-col` + content `flex-1 min-h-0` pour conserver le composer visible en bas
  - Optimisation perf: le panneau est **mont√© une seule fois**, puis on fait **hide/show** (pas de remount ‚Üí pas d‚Äôappels API √† chaque ouverture/fermeture)
  - Optimisation perf: switch **Jobs IA ‚Üî Chat** en hide/show (ChatPanel + QueueMonitor restent mont√©s)
  - Anti-reload: retour depuis ‚ÄúJobs IA‚Äù vers **la m√™me session** ne relance pas `selectSession()` (√©vite ‚ÄúChargement du d√©tail‚Ä¶‚Äù)
  - Nettoyage: suppression de `StreamMessageLegacy.svelte` (plus de variant legacy, `StreamMessage` couvre chat + job)
  - UI: scrollbar **uniformis√©e** (classe globale `.slim-scroll`) sur ChatPanel + Jobs IA + zones de d√©tail StreamMessage
  - Fix r√©activit√©: cl√© composite dans `{#each}` de QueueMonitor (`${job.id}-${job.status}-${job.completedAt || ''}`) pour forcer la mise √† jour de l'UI quand le status change (Svelte recr√©e les blocs DOM)
  - Fix UX: correction de `showDetailLoader` dans StreamMessage pour exclure les jobs (√©vite d'afficher "Chargement du d√©tail..." pour les jobs pending)
- [x] **QueueMonitor r√©utilis√© comme panel** (sans requalifier) :
  - `QueueMonitor` conserve le contenu existant, mais **sans bulle/wrapper fixed/header**
  - Le titre et le bouton poubelle sont d√©plac√©s dans le header du widget
- [x] **UI Chat (vue dans le widget)** :
  - [x] `ChatPanel.svelte` : liste sessions + messages + composer (envoi `POST /chat/messages`)
  - [x] Streaming c√¥t√© UI : r√©sum√© en gris (dur√©e + nb d'outils) + chevron + d√©tail (raisonnement/outils sans r√©sultat), stream du r√©sultat dans la bulle, puis refresh messages au `done/error` (**scroll coll√© en bas**)
  - [x] UX: d√®s `status: started`, afficher un loader "En cours‚Ä¶" dans la zone grise (avant reasoning/outils/r√©ponse)
  - [x] D√©placer la s√©lection de session dans le header du widget (`ChatWidget`) + actions **+** (nouvelle session locale) et **üóëÔ∏è** (supprimer conversation)
  - [x] API : `DELETE /api/v1/chat/sessions/:id` (cascade DB)
  - Streaming: r√©utiliser `streamHub` + `StreamMessage` (pas de 2·µâ composant de rendu)
    - `streamId` = `assistantMessageId`
    - `StreamMessage` est la brique unique pour afficher l‚Äôavancement (reasoning/tools/content) + historique
- [x] **Data fetch (non-streaming)** :
  - `GET /chat/sessions` + `GET /chat/sessions/:id/messages` pour recharger l'historique apr√®s refresh
  - SSE global `/streams/sse` seulement pour les messages en cours / nouveaux events (cache/replay = confort UX)
- [x] **Chat global (pas page-scoped)** :
  - Le chat est disponible **partout** (ChatWidget disponible via `+layout.svelte`)
  - Le contexte est automatiquement d√©tect√© depuis l'URL (route + id le cas √©ch√©ant), pas besoin de s√©lecteur UI d√©di√©
  - Le diff (Avant/Apr√®s) sera impl√©ment√© dans le Lot D

#### Convergence StreamMessage (Chat vs Jobs) ‚Äî analyse de r√©trofit
- **Constat** :
  - Le `ChatPanel` a aujourd'hui **l'ergonomie cible** (zone grise steps, r√©sum√© ‚ÄúRaisonnement X, N outils‚Äù, chevron + d√©tail).
  - `StreamMessage.svelte` existe d√©j√†, mais il est plut√¥t ‚Äújob progress compact‚Äù (√©tape + historique), et ne porte pas l'UX Chat.
- **Diff√©rences r√©elles Chat vs Job (faibles)** :
  - **Chat**: rendu du **r√©sultat** dans une bulle + remplacement par le contenu final quand `done`.
  - **Jobs**: pas de bulle de r√©ponse (ou pas toujours), mais on veut **la m√™me lecture** des steps (reasoning/tools) + historique.
  - **Hydratation historique**:
    - Chat: scopes user/session (endpoints `/chat/*`).
    - Jobs: scope ‚ÄústreamId‚Äù (ex: `job_<id>`, `company_<id>`), n√©cessite un endpoint g√©n√©rique `/streams/*`.
- **Plan (5 √©tapes)** :
  - [x] (1) Documenter cette convergence (section actuelle).
  - [x] (2) Remplacer `StreamMessage` par une version unifi√©e qui reprend l'UX du chat (backup: `StreamMessageLegacy.svelte`).
  - [x] (3) API: permettre la relecture d'historique par `streamId` (jobs inclus) avec `limit/since` (`GET /api/v1/streams/events/:streamId`).
  - [x] (4) Adapter `StreamMessage` au besoin QueueMonitor (variant `job`: steps + historique, sans bulle chat).
  - [x] (5) Adapter `QueueMonitor` pour utiliser `StreamMessage` (live SSE + historique API via `historySource="stream"`).

### Phase 4 : Int√©gration tool call dans le chat
- [x] **4.1 - UI : D√©tection automatique du contexte depuis la route** :
  - Dans `ChatPanel.svelte`, d√©tecter la route actuelle via `$page.route.id` et `$page.params`
  - Mapper les routes aux contextes :
    - `/cas-usage/[id]` ‚Üí `primaryContextType: 'usecase'`, `primaryContextId: $page.params.id`
    - `/dossiers/[id]` ‚Üí `primaryContextType: 'folder'`, `primaryContextId: $page.params.id`
    - `/entreprises/[id]` ‚Üí `primaryContextType: 'company'`, `primaryContextId: $page.params.id`
  - Modifier `sendMessage()` pour inclure `primaryContextType` et `primaryContextId` dans l'appel `POST /chat/messages`
  - G√©rer le cas o√π on n'est pas sur une route avec contexte (pas de tool disponible)
- [ ] **4.2 - API : Passage des tools √† OpenAI** :
  - [x] **4.2.1 - Cr√©er le tool `read_usecase`** :
    - Cr√©er `readUseCaseTool` dans `tools.ts` (param√®tre `useCaseId`, retourne le use case complet)
    - Cr√©er `readUseCase()` dans `tool-service.ts` pour lire le use case depuis la DB
    - Retourner la structure `use_cases.data` compl√®te
  - [x] **4.2.2 - Passer les tools √† OpenAI** :
    - Dans `chat-service.ts` ‚Üí `runAssistantGeneration()`, r√©cup√©rer le contexte depuis la session (`primaryContextType`, `primaryContextId`)
    - Importer `readUseCaseTool`, `updateUseCaseFieldTool`, `webSearchTool` et `webExtractTool` depuis `tools.ts`
    - Conditionner le passage des tools : ne passer `tools: [readUseCaseTool, updateUseCaseFieldTool, webSearchTool, webExtractTool]` que si `primaryContextType === 'usecase'`
    - Passer les tools √† `callOpenAIResponseStream()` dans les options
    - Enrichir le system prompt avec le contexte usecase pour guider l'IA
  - [x] **4.2.3 - Int√©gration des tools web (web_search, web_extract)** :
    - `web_search` : Recherche d'informations r√©centes sur le web pour trouver de nouvelles URLs ou obtenir des r√©sum√©s
    - `web_extract` : Extraction du contenu complet d'une ou plusieurs URLs existantes (r√©f√©rences du use case)
    - Correction du parsing de la r√©ponse Tavily : utiliser `raw_content` au lieu de `markdown`/`content` dans la structure `results[]`
    - Support de l'appel group√© : `web_extract` accepte un array d'URLs pour extraire plusieurs URLs en un seul appel
    - Workflow guid√© dans le system prompt : lire le use case ‚Üí extraire les URLs depuis `data.references` ‚Üí appeler `web_extract` une seule fois avec toutes les URLs
- [x] **4.3 - API : Gestion des tool calls dans le stream** :
  - Dans `runAssistantGeneration()`, g√©rer les √©v√©nements `tool_call_start`, `tool_call_delta`, `done`
  - Pour `tool_call_start` : initialiser un objet pour stocker les arguments du tool call
  - Pour `tool_call_delta` : accumuler les arguments JSON (comme pour `content_delta`)
  - Boucle it√©rative pour g√©rer plusieurs rounds de tool calls (max 10 it√©rations)
  - Collecter tous les tool calls avant de les ex√©cuter
- [x] **4.4 - API : Ex√©cution des tools** :
  - Apr√®s avoir collect√© tous les tool calls dans un round, ex√©cuter chaque tool :
    - **Pour `read_usecase`** :
      - Parser les arguments accumul√©s (`useCaseId`)
      - V√©rifier que `useCaseId` correspond au `primaryContextId` de la session (s√©curit√©)
      - Appeler `toolService.readUseCase()` avec `useCaseId`
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'` avec le use case complet)
    - **Pour `update_usecase_field`** :
      - Parser les arguments accumul√©s (`useCaseId`, `updates`)
      - V√©rifier que `useCaseId` correspond au `primaryContextId` de la session (s√©curit√©)
      - Appeler `toolService.updateUseCaseFields()` avec :
        - `useCaseId` depuis les arguments
        - `updates` depuis les arguments
        - `sessionId` et `assistantMessageId` pour l'historique
        - `toolCallId` pour la tra√ßabilit√©
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
    - **Pour `web_search`** :
      - Parser les arguments accumul√©s (`query`)
      - Appeler `searchWeb()` depuis `tools.ts` (API Tavily)
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream avec les r√©sultats de recherche
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
    - **Pour `web_extract`** :
      - Parser les arguments accumul√©s (`urls` - array d'URLs)
      - Appeler `extractUrlContent()` pour chaque URL (en parall√®le via `Promise.all`)
      - √âcrire l'√©v√©nement `tool_call_result` dans le stream avec les contenus extraits
      - Construire le r√©sultat au format OpenAI (message `role: 'tool'`)
  - Ajouter tous les r√©sultats des tools √† la conversation pour continuer le stream dans le round suivant
- [x] **4.5 - API : Transmission du contexte au mod√®le** :
  - Enrichir le `systemPrompt` dans `runAssistantGeneration()` pour inclure le contexte :
    - Si `primaryContextType === 'usecase'` : "Tu travailles sur le use case {primaryContextId}. Tu peux utiliser le tool `read_usecase` pour lire son √©tat actuel, puis `update_usecase_field` pour modifier ses champs."
    - Ajout des tools web : `web_search` pour rechercher de nouvelles informations, `web_extract` pour extraire le contenu des r√©f√©rences existantes
    - Workflow guid√© pour l'analyse des r√©f√©rences : lire le use case ‚Üí extraire URLs depuis `data.references` ‚Üí appeler `web_extract` une seule fois avec toutes les URLs
    - Instructions explicites pour regrouper les URLs dans un seul appel `web_extract` (√©vite les appels multiples)
  - Alternative : inclure le contexte dans les messages de conversation (moins recommand√©)

- [x] **4.6 - Tests et validation (manuels)** :
  - [x] Test manuel : sur `/cas-usage/[id]`, demander une modification du use case et v√©rifier que le tool est appel√©
  - [x] V√©rifier que les modifications sont bien √©crites en DB (`use_cases.data`)
  - [x] V√©rifier que l'historique est cr√©√© (`context_modification_history`, `chat_contexts`)
  - [x] V√©rifier que le mod√®le continue la conversation apr√®s l'ex√©cution du tool
  - **Note** : Tests automatis√©s d√©taill√©s dans Phase 5

**Crit√®res de validation Phase 4** :
- ‚úÖ Le contexte est automatiquement d√©tect√© depuis la route
- ‚úÖ Le tool est pass√© √† OpenAI uniquement quand le contexte est `usecase`
- ‚úÖ Les tool calls sont g√©r√©s dans le stream
- ‚úÖ Le tool est ex√©cut√© et les modifications sont appliqu√©es en DB
- ‚úÖ Le mod√®le continue la conversation apr√®s l'ex√©cution du tool
- ‚úÖ L'historique des modifications est trac√©

### Phase 5 : Tests

> **R√©f√©rence** : Strat√©gie de test d√©finie dans `.cursor/rules/testing.mdc` (pyramide : 70% unit, 20% int√©gration, 10% E2E)

#### 5.0 - V√©rifications pr√©liminaires (Typecheck & Lint) ‚úÖ

> **Note** : Avant de commencer les tests fonctionnels, s'assurer que le code compile et respecte les r√®gles de lint.

- [x] **Typecheck API** :
  - [x] `make typecheck-api` : V√©rifier que TypeScript compile sans erreurs
  - [x] Corriger toutes les erreurs de type avant de continuer
  - Corrections effectu√©es :
    - Fix type `currentMessages` pour accepter `role: 'tool'` dans `chat-service.ts`
    - Suppression des imports `executeWithTools` obsol√®tes dans `context-company.ts` et `executive-summary.ts`

- [x] **Typecheck UI** :
  - [x] `make typecheck-ui` : V√©rifier que SvelteKit compile sans erreurs
  - [x] Aucune erreur de type (0 errors, 0 warnings)

- [x] **Lint API** :
  - [x] `make lint-api` : V√©rifier que le code API respecte les r√®gles ESLint
  - [x] Corriger tous les warnings/erreurs de lint avant de continuer
  - Corrections effectu√©es :
    - `maxIterations` chang√© en `const` dans `chat-service.ts`
    - Variable `streamDone` supprim√©e (non utilis√©e) dans `chat-service.ts`
    - Variable `nextData` supprim√©e (non utilis√©e) dans `tool-service.ts`
    - Fonction `setAtPath` supprim√©e (non utilis√©e) dans `tool-service.ts`
    - Import `callOpenAI` non utilis√© supprim√© dans `tools.ts`

- [x] **Lint UI** :
  - [x] `make lint-ui` : V√©rifier que le code UI respecte les r√®gles ESLint/Svelte
  - [x] Aucune erreur de lint

**Commandes** :
- `make typecheck-api`
- `make typecheck-ui`
- `make lint-api`
- `make lint-ui`

#### 5.1 - Tests unitaires API (70% de la couverture) ‚úÖ

> **Note** : Dans ce projet, les tests unitaires testent soit des **fonctions pures** (sans d√©pendances), soit des **services isol√©s** (logique m√©tier d'un service, m√™me s'ils utilisent DB PostgreSQL de test via Docker). La distinction cl√© : **pas d'endpoints HTTP** (`app` de Hono). Les services qui utilisent la DB PostgreSQL de test sont consid√©r√©s comme unitaires s'ils testent la logique m√©tier isol√©e (ex: `session-manager.test.ts`, `challenge-manager.test.ts`).

**Fichiers √† cr√©er** : `api/tests/unit/stream-service.test.ts`, `api/tests/unit/tool-service.test.ts`

- [x] **Stream Service** (`api/tests/unit/stream-service.test.ts`) ‚úÖ :
  - [x] Setup : `beforeEach`/`afterEach` pour cleanup DB PostgreSQL de test
  - [x] `writeStreamEvent()` : √©criture dans `chat_stream_events` avec s√©quence correcte (DB PostgreSQL de test)
  - [x] `writeStreamEvent()` : PostgreSQL NOTIFY avec payload minimal (test v√©rifie que la fonction s'ex√©cute sans erreur)
  - [x] `getNextSequence()` : incr√©mentation s√©quentielle par `stream_id` (DB PostgreSQL de test)
  - [x] `readStreamEvents()` : lecture avec filtres `sinceSequence` et `limit` (DB PostgreSQL de test)
  - [x] `generateStreamId()` : g√©n√©ration d√©terministe pour diff√©rents contextes (fonction pure)
  - [x] Gestion des s√©quences : unicit√©, ordre strict, d√©duplication (DB PostgreSQL de test)

- [x] **Tool Service** (`api/tests/unit/tool-service.test.ts`) ‚úÖ :
  - [x] Setup : `beforeEach` ‚Üí cr√©er use case de test en DB PostgreSQL, `afterEach` ‚Üí cleanup
  - [x] `readUseCase()` : lecture depuis DB avec validation `useCaseId` (DB PostgreSQL de test)
  - [x] `updateUseCaseFields()` : validation des arguments (useCaseId, updates array)
  - [x] `updateUseCaseFields()` : utilisation de `jsonb_set` pour mises √† jour partielles (DB PostgreSQL de test)
  - [x] `updateUseCaseFields()` : √©criture dans `context_modification_history` (DB PostgreSQL de test)
  - [x] `updateUseCaseFields()` : snapshots avant/apr√®s dans `chat_contexts` (DB PostgreSQL de test)
  - [x] `updateUseCaseFields()` : PostgreSQL NOTIFY `usecase_update` (test v√©rifie que la fonction s'ex√©cute sans erreur)
  - [x] Gestion des erreurs : paths invalides, valeurs invalides, limites (max 50 updates)

- [x] **Tools (web_extract)** (`api/tests/unit/tools.test.ts`) ‚úÖ :
  - [x] `extractUrlContent()` : appel avec une seule URL (compatibilit√©, mock Tavily API)
  - [x] `extractUrlContent()` : appel avec array d'URLs (un seul appel Tavily, mock Tavily API)
  - [x] `extractUrlContent()` : parsing correct de `raw_content` depuis `results[]` (mock Tavily response)
  - [x] `extractUrlContent()` : gestion erreur HTTP (mock fetch avec `resp.ok = false`)
  - [x] `extractUrlContent()` : gestion contenu vide (warning log, retour structure correcte)
  - [x] Validation array vide dans `executeWithToolsStream` : rejet avec erreur claire (mock tool call avec `{"urls":[]}`) - Note: Test√© indirectement via tests d'int√©gration

- [ ] **Utilitaires purs** (si fonctions utilitaires cr√©√©es) :
  - [ ] Fonctions de parsing/formatage : tests sans DB (fonctions pures)
  - [ ] Fonctions de validation : tests sans DB (fonctions pures)

> **Note sur Chat Service et OpenAI Service** : `chat-service.ts` et `openai.ts` contiennent de la logique qui n√©cessite des appels OpenAI r√©els ou des mocks complexes. Ces services seront test√©s en **int√©gration** via les endpoints HTTP (`api/tests/api/chat.test.ts`, `api/tests/ai/chat-tools.test.ts`) plut√¥t qu'en unitaire.

**Commandes** :
- `make test-api-unit SCOPE=tests/unit/stream-service.test.ts`
- `make test-api-unit SCOPE=tests/unit/tool-service.test.ts`
- `make test-api-unit SCOPE=tests/unit/tools.test.ts`

#### 5.2 - Tests d'int√©gration API (20% de la couverture)

> **Note** : Les tests d'int√©gration testent les **endpoints HTTP complets** avec `app` de Hono. Ils utilisent DB PostgreSQL de test (via Docker) et testent le flux complet : requ√™te HTTP ‚Üí authentification ‚Üí service ‚Üí DB ‚Üí r√©ponse HTTP. Utiliser `createAuthenticatedUser()` et `authenticatedRequest()` depuis `api/tests/utils/auth-helper.ts`. Pattern : `beforeEach` pour cr√©er user, `afterEach` pour `cleanupAuthData()`.

**Fichiers √† cr√©er** : `api/tests/api/chat.test.ts`, `api/tests/api/streams.test.ts`, `api/tests/ai/chat-tools.test.ts`

> **Note sur Chat Service** : `chat-service.ts` contient √† la fois de la logique m√©tier (cr√©ation sessions/messages) ET de la g√©n√©ration IA (appels OpenAI). Les tests de logique m√©tier pure peuvent √™tre unitaires (DB SQLite), mais `runAssistantGeneration()` avec appels OpenAI r√©els sera test√© en int√©gration (endpoints HTTP).

- [x] **Endpoints Chat** (`api/tests/api/chat.test.ts`) ‚úÖ :
  - [x] Setup : `beforeEach` ‚Üí `createAuthenticatedUser('editor')`, `afterEach` ‚Üí `cleanupAuthData()`
  - [x] `POST /api/v1/chat/messages` : cr√©ation session si n√©cessaire (via `authenticatedRequest`)
  - [x] `POST /api/v1/chat/messages` : enregistrement message user
  - [x] `POST /api/v1/chat/messages` : job `chat_message` enfil√© en queue
  - [x] `POST /api/v1/chat/messages` : retour `sessionId`, `userMessageId`, `assistantMessageId`, `streamId`
  - [x] `GET /api/v1/chat/sessions` : liste sessions pour user (filtr√©e par user_id)
  - [x] `GET /api/v1/chat/sessions/:id/messages` : liste messages ordonn√©e
  - [x] `GET /api/v1/chat/sessions/:id/stream-events` : batch events pour session
  - [x] `GET /api/v1/chat/messages/:id/stream-events` : events pour message
  - [x] `DELETE /api/v1/chat/sessions/:id` : suppression avec cascade
  - [x] Validation : contexte automatique depuis `primaryContextType`/`primaryContextId` (dans body POST)
  - [ ] Validation : erreurs (session non trouv√©e ‚Üí 404, user non autoris√© ‚Üí 403, pas d'auth ‚Üí 401)

- [ ] **Endpoints Streams** (`api/tests/api/streams.test.ts`) :
  - [ ] Setup : `beforeEach` ‚Üí `createAuthenticatedUser('editor')`, `afterEach` ‚Üí `cleanupAuthData()`
  - [ ] `GET /api/v1/streams/sse` : connexion SSE avec filtrage par `streamId` (query param)
  - [ ] `GET /api/v1/streams/sse` : r√©ception √©v√©nements en temps r√©el (NOTIFY) - mock EventSource ou test manuel
  - [ ] `GET /api/v1/streams/events/:streamId` : historique avec `limit` et `sinceSequence` (via `authenticatedRequest`)
  - [ ] Validation : √©v√©nements `reasoning_delta`, `content_delta`, `tool_call_*`, `done`, `error`
  - [ ] Validation : ordre s√©quentiel, d√©duplication
  - [ ] Validation : 401 sans authentification

- [ ] **Tool Calls Int√©gration** (`api/tests/ai/chat-tools.test.ts`) :
  - [ ] Setup : `beforeEach` ‚Üí `createAuthenticatedUser('editor')`, cr√©er use case de test via endpoint, `afterEach` ‚Üí `cleanupAuthData()`
  - [ ] Parcours complet : `POST /api/v1/chat/messages` avec `primaryContextType: 'usecase'` ‚Üí job enfil√© ‚Üí tool call `read_usecase` ‚Üí r√©sultat dans stream
  - [ ] Parcours complet : `POST /api/v1/chat/messages` ‚Üí tool call `update_usecase_field` ‚Üí DB mise √† jour (v√©rifier `use_cases.data` via `GET /api/v1/use-cases/:id`)
  - [ ] Parcours complet : `POST /api/v1/chat/messages` ‚Üí tool call `web_search` ‚Üí r√©sultats dans stream (mock Tavily API si n√©cessaire pour √©viter co√ªts)
  - [ ] Parcours complet : `POST /api/v1/chat/messages` ‚Üí tool call `web_extract` (array URLs) ‚Üí contenus extraits (mock Tavily API, v√©rifier un seul appel Tavily pour plusieurs URLs)
  - [ ] Validation `web_extract` array vide : tool call avec `{"urls":[]}` ‚Üí erreur claire dans stream (pas d'appel Tavily)
  - [ ] V√©rification : `context_modification_history` cr√©√© avec bonnes valeurs (lecture DB directe via `db.select()`)
  - [ ] V√©rification : `chat_contexts` avec snapshots avant/apr√®s (lecture DB directe)
  - [ ] V√©rification : `chat_stream_events` contient tous les √©v√©nements (reasoning, content, tools) - lecture via `GET /api/v1/streams/events/:streamId`
  - [ ] V√©rification : `use_cases.data` mis √† jour avec `jsonb_set` (partiel, v√©rifier que seuls les champs modifi√©s changent) - lecture via endpoint
  - [ ] V√©rification : PostgreSQL NOTIFY `usecase_update` √©mis (test manuel ou v√©rification via SSE si applicable)
  - [ ] Validation s√©curit√© : `useCaseId` doit correspondre au contexte de session (test avec `useCaseId` diff√©rent ‚Üí erreur 403/400)
  - [ ] Validation : boucle it√©rative (plusieurs rounds de tool calls) - test avec prompt demandant plusieurs modifications
  - [ ] Validation : continuation conversation apr√®s tool call (envoyer un 2e message via `POST /api/v1/chat/messages`, v√©rifier historique via `GET /api/v1/chat/sessions/:id/messages`)

- [x] **Chat AI complet** (`api/tests/ai/chat-sync.test.ts`) ‚úÖ :
  - [x] Setup : `beforeEach` ‚Üí `createAuthenticatedUser('editor')` + cleanup, `afterEach` ‚Üí `cleanupAuthData()`
  - [x] G√©n√©ration assistant response avec IA (test simple, timeout 15s, max 10 tentatives * 1s)
  - [x] G√©n√©ration avec tool calls (`read_usecase`) dans contexte usecase
  - [x] Validation `web_extract` : pas d'appel avec array vide (test avec prompt simple)
  - [x] Maintien contexte conversation : plusieurs messages dans m√™me session
  - [x] V√©rification contenu final : message assistant mis √† jour en DB apr√®s compl√©tion job
  - [x] V√©rification stream events : structure correcte apr√®s g√©n√©ration

- [ ] **G√©n√©rations classiques - Mise √† jour tests existants** :
  - [x] V√©rifier que les services utilisent bien `executeWithToolsStream` (pas `executeWithTools`) ‚úÖ
    - [x] `executive-summary.ts` : utilise `executeWithToolsStream` avec `streamId` optionnel
    - [x] `context-usecase.ts` : utilise `executeWithToolsStream`
    - [x] `context-company.ts` : utilise `executeWithToolsStream`
  - [ ] **Ajouter v√©rifications dans tests existants** :
    - [ ] `api/tests/ai/executive-summary-sync.test.ts` : v√©rifier que les √©v√©nements sont √©crits dans `chat_stream_events` apr√®s g√©n√©ration
      - [ ] V√©rifier `streamId` d√©terministe : `job_<jobId>` (via `generateStreamId` avec `jobId`)
      - [ ] V√©rifier `message_id=null` pour g√©n√©rations classiques
      - [ ] V√©rifier pr√©sence d'√©v√©nements `content_delta`, `done` (et `tool_call_*` si `web_extract`/`web_search` utilis√©s)
    - [ ] `api/tests/ai/usecase-generation-*.test.ts` : ajouter v√©rifications `chat_stream_events`
    - [ ] `api/tests/ai/company-enrichment-sync.test.ts` : ajouter v√©rifications `chat_stream_events`
  - [x] Validation : `web_extract` avec array d'URLs ‚Üí un seul appel Tavily ‚úÖ (test√© dans `tools.test.ts`)
  - [x] Validation : `web_extract` avec array vide ‚Üí erreur claire ‚úÖ (test√© dans `chat-sync.test.ts`)

**Commandes** :
- `make test-api SCOPE=tests/api/chat.test.ts`
- `make test-api SCOPE=tests/api/streams.test.ts`
- `make test-api-ai SCOPE=tests/ai/chat-tools.test.ts`
- `make test-api-ai SCOPE=tests/ai/classic-generations.test.ts`

#### 5.3 - Tests E2E Playwright (10% de la couverture)

> **Note** : Les tests E2E testent les composants Svelte via l'UI r√©elle. Pas d'auth explicite (utilisent l'auth r√©elle de l'app). Pattern : `test.describe()` pour grouper, `test()` pour chaque sc√©nario. Utiliser `page.goto()`, `page.locator()`, `expect().toBeVisible()`.

**Fichier √† cr√©er** : `e2e/tests/chat.spec.ts`

- [ ] **Parcours Chat de base** :
  - [ ] Ouvrir ChatWidget depuis n'importe quelle page
  - [ ] Cr√©er une nouvelle session
  - [ ] Envoyer un message utilisateur
  - [ ] V√©rifier affichage reasoning en streaming (si disponible)
  - [ ] V√©rifier affichage r√©ponse assistant
  - [ ] V√©rifier scroll automatique en bas
  - [ ] Fermer et rouvrir le widget : session conserv√©e

- [ ] **Parcours Tool Call sur Use Case** :
  - [ ] Naviguer vers `/cas-usage/[id]` (use case existant)
  - [ ] Ouvrir ChatWidget (clic sur bulle chat en bas √† droite)
  - [ ] V√©rifier que le contexte est d√©tect√© (pas de s√©lecteur visible)
  - [ ] Envoyer message : "Reformule le probl√®me en bullet points"
  - [ ] V√©rifier affichage reasoning en streaming (si disponible)
  - [ ] V√©rifier tool `read_usecase` appel√© (dans d√©tail d√©pliable de `StreamMessage`)
  - [ ] V√©rifier tool `update_usecase_field` appel√© (dans d√©tail d√©pliable)
  - [ ] V√©rifier modification appliqu√©e en DB (refresh page, v√©rifier contenu)
  - [ ] V√©rifier historique visible dans `StreamMessage` (accord√©on d√©pli√©)
  - [ ] V√©rifier refresh automatique UI apr√®s modification (SSE, pas besoin de refresh)

- [ ] **Parcours Tool Call Web** :
  - [ ] Naviguer vers `/cas-usage/[id]` avec r√©f√©rences (use case avec `data.references` rempli)
  - [ ] Ouvrir ChatWidget
  - [ ] Envoyer message : "Analyse les r√©f√©rences en d√©tail"
  - [ ] V√©rifier tool `read_usecase` appel√© (dans d√©tail d√©pliable)
  - [ ] V√©rifier tool `web_extract` appel√© avec array d'URLs (un seul appel, v√©rifier dans d√©tail)
  - [ ] V√©rifier contenus extraits affich√©s dans r√©ponse assistant (texte visible)
  - [ ] Cas sans r√©f√©rences : use case sans `data.references` ‚Üí v√©rifier que `web_extract` n'est pas appel√© avec array vide (ou erreur claire si appel√©)

- [ ] **Parcours Multi-sessions** :
  - [ ] Cr√©er plusieurs sessions pour le m√™me use case
  - [ ] Basculer entre sessions
  - [ ] V√©rifier messages conserv√©s par session
  - [ ] Supprimer une session
  - [ ] V√©rifier autres sessions intactes

- [ ] **Parcours QueueMonitor int√©gr√©** :
  - [ ] Basculer Chat ‚Üî Jobs IA dans ChatWidget
  - [ ] V√©rifier jobs affich√©s avec streaming
  - [ ] V√©rifier `StreamMessage` pour jobs (variant `job`)
  - [ ] V√©rifier historique stream pour jobs

- [ ] **Gestion erreurs** :
  - [ ] Message avec erreur OpenAI : v√©rifier affichage erreur
  - [ ] Tool call avec arguments invalides : v√©rifier message d'erreur
  - [ ] Tool call avec `useCaseId` ne correspondant pas au contexte : v√©rifier rejet
  - [ ] Tool call `web_extract` avec array vide : v√©rifier erreur claire affich√©e (pas d'erreur 400 Tavily)

**Commande** :
- `make test-e2e E2E_test=tests/chat.spec.ts`

#### 5.4 - Tests UI (unitaires SvelteKit - stores et utilitaires uniquement)

> **Note** : Les tests UI testent uniquement les **stores** et **utilitaires**, pas les composants Svelte. Les composants (`ChatWidget`, `ChatPanel`, `StreamMessage`) sont test√©s en E2E uniquement. Utiliser `mockFetchJsonOnce()` depuis `ui/tests/test-setup.ts` pour mocker les appels API.

**Fichiers √† cr√©er** : `ui/tests/stores/streamHub.test.ts`, `ui/tests/utils/stream.test.ts` (si utilitaires sp√©cifiques)

- [ ] **streamHub Store** (`ui/tests/stores/streamHub.test.ts`) :
  - [ ] Connexion SSE (mock EventSource)
  - [ ] Agr√©gation deltas (reasoning/content)
  - [ ] Cache/replay des √©v√©nements
  - [ ] Abonnements cibl√©s par `streamId`
  - [ ] Gestion des erreurs de connexion

- [ ] **Utilitaires stream** (`ui/tests/utils/stream.test.ts`) (si utilitaires cr√©√©s) :
  - [ ] Parsing des √©v√©nements SSE
  - [ ] Formatage des donn√©es stream
  - [ ] Helpers de transformation

**Commandes** :
- `make test-ui SCOPE=tests/stores/streamHub.test.ts`
- `make test-ui SCOPE=tests/utils/stream.test.ts` (si applicable)

#### 5.5 - Crit√®res de validation Phase 5

- [x] **Pr√©requis** : Typecheck et lint passent (`make typecheck-api`, `make typecheck-ui`, `make lint-api`, `make lint-ui`) ‚úÖ
- [ ] Tous les tests unitaires passent (`make test-api-unit`, `make test-ui-unit`)
- [ ] Tous les tests d'int√©gration passent (`make test-api`, `make test-api-ai`)
- [ ] Tous les tests E2E passent (`make test-e2e`)
- [ ] Couverture minimale : 70% unit, 20% int√©gration, 10% E2E (selon pyramide)
- [ ] Tests isol√©s et r√©p√©tables
- [ ] Pas de d√©pendances externes pour tests unitaires (mocks)
- [ ] Tests d'int√©gration avec DB SQLite de test
- [ ] Tests E2E avec Docker Compose complet

### Phase 6 : UndoBar (apr√®s validation des tests)
- [ ] **UndoBar** :
  - Bouton "Annuler" + preview de la derni√®re modification (via `context_modification_history` + `chat_contexts`)
  - Option: confirmation humaine pour actions ‚ö†Ô∏è
  - **Note** : √Ä impl√©menter apr√®s validation compl√®te des tests (Phase 5) pour garantir la stabilit√© de l'annulation

### Phase 7 : Documentation et finalisation
- [ ] Mettre √† jour la documentation OpenAPI
- [ ] V√©rifier que tous les tests passent (`make test`)
- [ ] V√©rifier le build (`make build`)
- [ ] Ex√©cuter les tests E2E (`make test-e2e`)
- [ ] V√©rifier CI GitHub Actions

## D√©cisions techniques

- **Parcours impl√©ment√©** : Use case uniquement (folder sera ajout√© ult√©rieurement)
- **Mod√®le OpenAI** : `gpt-4.1-nano` par d√©faut, r√©cup√©r√© via `settingsService.getAISettings().defaultModel`
- **Interface utilisateur** : Popup flottant similaire √† `QueueMonitor.svelte`, avec la queue en accord√©on dans le m√™me conteneur
- **Validation** : Pas de confirmation interm√©diaire. Feature d'annulation du dernier changement au niveau de l'objet (√† terme √† la maille du sous-objet `data.description`)

## Architecture & Incoh√©rences identifi√©es avec le plan initial

### Incoh√©rences identifi√©es

1. **Phase 2 vs Phase 3** : Le plan initial met "Service de streaming" en Phase 3, mais la couche streaming doit √™tre pr√™te AVANT les endpoints chat (Phase 2), car ils en d√©pendent.

2. **Queue pour chat** : le plan initial disait "direct sans queue", mais on a choisi un job `chat_message` pour pr√©parer le scaling (workers d√©di√©s). Le streaming reste en temps r√©el via `chat_stream_events` + SSE global.

3. **Architecture streaming** : Il faut une **couche streaming partag√©e** qui sert :
   - Les g√©n√©rations classiques (via queue) - qui deviendront plus transparentes pour tools/r√©flexion
   - Le chat (via queue `chat_message`, scalable)
   - M√©thodes partag√©es pour √©viter la duplication

### Approche progressive valid√©e

**Phase 2A - POC sur g√©n√©ration d'entreprise** :
- Cas le plus simple (pas de tool calls complexes, pas de multi-√©tapes)
- Permet de valider l'architecture compl√®te (streaming + DB + NOTIFY + queue)
- **Un seul test UAT complet** suffit avant g√©n√©ralisation
- G√©n√©ralisation ensuite (Phase 2B) aux autres g√©n√©rations classiques

**Gestion de la queue** :
- La queue continue de fonctionner normalement
- Elle attend toujours le r√©sultat final de `enrichCompany` (comportement inchang√©)
- Le streaming est transparent : √©v√©nements √©crits pendant l'ex√©cution, r√©sultat final collect√© et retourn√©

**R√©cup√©ration du r√©sultat final** :
- `enrichCompany` agr√®ge tous les `content_delta` pour reconstruire le JSON complet
- Parse le JSON comme avant (compatibilit√© totale)
- Retourne le r√©sultat final (comme avant)
- La queue met √† jour la DB avec ce r√©sultat (comportement inchang√©)

## Commits & Progress

- [x] **Phase 1** : Ajout des tables chat dans le sch√©ma Drizzle
  - Tables cr√©√©es : `chat_sessions`, `chat_messages`, `chat_contexts`, `chat_stream_events`, `context_modification_history`
  - Migration g√©n√©r√©e : `0011_past_drax.sql`
  - Migration appliqu√©e avec succ√®s
  - V√©rification : toutes les tables pr√©sentes en base

- [x] **Phase 2A (POC streaming entreprise + UI monitoring)** : Streaming end-to-end + affichage temps r√©el
  - **API**
    - SSE global : `GET /api/v1/streams/sse` (flux unique) + `LISTEN/NOTIFY` (`stream_events`, `job_events`, `company_events`)
    - `generateStreamId` d√©terministe pour jobs (`job_<jobId>`) + **enrich entreprise streamId** : `company_<companyId>`
    - `NOTIFY job_events` (queue) + `NOTIFY company_events` (CRUD + transitions de statut)
    - Typage ‚Äúsafe‚Äù sur `executeWithToolsStream` (`event.data` = `unknown`) pour √©viter les r√©gressions TS/ESLint
    - Compat OpenAI : d√©sactivation de `reasoning.summary` pour les mod√®les `gpt-4.1-*` (ex: `gpt-4.1-nano-*`) pour √©viter un 400
  - **UI**
    - Nouveau composant `StreamMessage` (prop `streamId`) : derni√®re √©tape + historique d√©pliable, deltas cumul√©s, auto-scroll bas, placeholder sans waiter
    - `streamHub` : connexion SSE unique + abonnements cibl√©s (`setStream`, `setJobUpdates`) + cache/replay + agr√©gation des deltas
    - `QueueMonitor` : bouton toujours √† jour (job_update m√™me repli√©) + suivi de stream via `StreamMessage`
    - Liste entreprises : remplacement du waiter en mode `enriching` par `StreamMessage` sur `company_<id>`
    - Raffinements `StreamMessage` : chevron sur la ligne du titre + scrollbar discr√®te (zones scrollables)

- [x] **Phase 2A.1** : Couche OpenAI Streaming
  - Cr√©√© `callOpenAIStream` dans `openai.ts`
  - Retourne `AsyncIterable<StreamEvent>`
  - G√®re content_delta, tool_call_start, tool_call_delta, status, error, done
  - Mutualise les valeurs par d√©faut du mod√®le via `settingsService.getAISettings().defaultModel`

- [x] **Phase 2A.2** : Service Stream Partag√©
  - Cr√©√© `stream-service.ts` avec `writeStreamEvent`, `generateStreamId`, `getNextSequence`, `readStreamEvents`
  - √âcriture dans `chat_stream_events` avec `message_id=null` pour g√©n√©rations classiques
  - PostgreSQL NOTIFY pour temps r√©el (payload minimal)

- [x] **Phase 2A.3** : Adapter enrichCompany pour streaming
  - Cr√©√© `enrichCompanyStream` qui utilise `callOpenAIStream`
  - Collecte le r√©sultat final (agr√®ge content_delta)
  - G√®re les tool calls (web_search, web_extract) en streaming
  - √âcrit tous les √©v√©nements dans `chat_stream_events`
  - `enrichCompany` accepte maintenant `streamId?` optionnel

- [x] **Phase 2A.4** : Int√©gration queue
  - Modifi√© `processCompanyEnrich` pour g√©n√©rer un `streamId` et le passer √† `enrichCompany`
  - La queue attend toujours le r√©sultat final (comportement inchang√©)

- [x] **Phase 2B (streaming dossiers + cas d'usage + synth√®se)** : G√©n√©ralisation aux g√©n√©rations classiques
  - **API**
    - Jobs : `use_case_list`, `use_case_detail`, `executive_summary` passent par `executeWithToolsStream`
    - `streamId` d√©terministes par entit√© : `folder_<folderId>`, `usecase_<useCaseId>`
    - √âv√©nements temps r√©el : `NOTIFY folder_events/usecase_events` + SSE `folder_update/usecase_update`
  - **UI**
    - Vues `/dossiers` et `/cas-usage` (liste + d√©tail) : suivi via SSE + `StreamMessage` (plus de polling)
    - Ergonomie cartes : suppression des badges jaunes ‚ÄúG√©n√©ration‚Ä¶‚Äù, `StreamMessage` plac√© aux bons endroits
    - Dossiers : masque le compteur ‚Äú0 cas d‚Äôusage‚Äù pendant la g√©n√©ration, et ‚ÄúS√©lectionn√©‚Äù affich√© dans le footer (pas dans le corps)

## Status
- **Progress**: Phase 1 + Phase 2A (POC entreprise) + Phase 2B + Phase 2C + Phase 2D + Phase 2E (Tool Service) + Phase 3 (Widget global Chat/Queue + UI chat) + Phase 4 (Int√©gration tool call) ‚úÖ
- **Current**: Phase 5 - Tests (unitaires, int√©gration, E2E)
- **Next**:
  - Tests : Phase 5 (d√©taill√©e ci-dessous)
  - UndoBar : Phase 6 (apr√®s validation des tests)
  - Documentation : Phase 7

## R√©sum√© des modifications depuis main

**31 commits** avec **8152 insertions** et **908 suppressions** sur **42 fichiers**.

**Principales fonctionnalit√©s impl√©ment√©es** :
- ‚úÖ Architecture streaming compl√®te (OpenAI ‚Üí DB ‚Üí NOTIFY ‚Üí SSE)
- ‚úÖ Service chat avec sessions et messages
- ‚úÖ Tools : `read_usecase`, `update_usecase_field`, `web_search`, `web_extract`
- ‚úÖ UI : ChatWidget unifi√© (Chat + QueueMonitor), ChatPanel, StreamMessage
- ‚úÖ D√©tection automatique du contexte depuis la route
- ‚úÖ Historique complet (stream-events, modification history, snapshots)
- ‚úÖ Refresh automatique UI apr√®s modifications (SSE events)

**Fichiers principaux cr√©√©s/modifi√©s** :
- `api/src/services/chat-service.ts` (530 lignes)
- `api/src/services/stream-service.ts` (155 lignes)
- `api/src/services/tool-service.ts` (246 lignes)
- `api/src/services/tools.ts` (376 lignes modifi√©es)
- `ui/src/lib/components/ChatWidget.svelte` (263 lignes)
- `ui/src/lib/components/ChatPanel.svelte` (380 lignes)
- `ui/src/lib/components/StreamMessage.svelte` (412 lignes)
- `ui/src/lib/stores/streamHub.ts` (268 lignes)

## Scope
- **API** : Nouveaux endpoints chat, streaming SSE, tools
- **UI** : Nouveaux composants chat-stream, int√©gration dans vues existantes
- **DB** : Nouvelles tables pour chat, streaming, historique
- **Tests** : Unit, int√©gration, E2E pour le parcours complet
- **CI** : V√©rification que les tests passent dans GitHub Actions

## R√©f√©rences
- **Sp√©cification compl√®te** : `spec/SPEC_CHATBOT.md` (source de v√©rit√© pour les Lots A, B, C, D, E)
- **Strat√©gie de test** : `.cursor/rules/testing.mdc` (pyramide : 70% unit, 20% int√©gration, 10% E2E)
- **Lot A d√©taill√©** : `spec/SPEC_CHATBOT.md` lignes 703-723
- **Mod√®le de donn√©es** : `spec/SPEC_CHATBOT.md` lignes 185-571
- **Architecture streaming** : `spec/SPEC_CHATBOT.md` lignes 120-138
- **Composants UI** : `spec/SPEC_CHATBOT.md` lignes 149-160
