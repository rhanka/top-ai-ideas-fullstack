# Feature: Lot A ‚Äî Mise √† jour cibl√©e d'un objet (Chatbot)

## Objective
Impl√©menter la fonctionnalit√© de base du chatbot permettant √† l'IA de proposer et d'appliquer une am√©lioration cibl√©e sur un use case existant avec reasoning en temps r√©el et tra√ßabilit√© compl√®te. Le parcours folder sera ajout√© ult√©rieurement.

**Valeur m√©tier** : D√©monstration client d√®s le premier incr√©ment. L'IA propose et applique une am√©lioration cibl√©e sur un objet m√©tier existant avec reasoning temps r√©el et tra√ßabilit√©.

**Port√©e fonctionnelle** : Mise √† jour de `use_cases.data.description` uniquement pour cette premi√®re it√©ration (le parcours folder sera ajout√© ult√©rieurement).

**Couverture CU** : CU-001, CU-003, CU-004 (minimal), CU-002 (basique), CU-010, CU-016

## Plan / Todo

### Phase 1 : Mod√®le de donn√©es et migrations ‚úÖ
- [x] Cr√©er les tables n√©cessaires dans le sch√©ma Drizzle :
  - [x] `chat_sessions` (sessions de chat utilisateur)
  - [x] `chat_messages` (messages de conversation avec reasoning)
  - [x] `chat_contexts` (liaison sessions ‚Üî objets m√©tier)
  - [x] `chat_stream_events` (√©v√©nements de streaming)
  - [x] `context_modification_history` (historique des modifications)
- [x] G√©n√©rer les migrations Drizzle (`make db-generate`) ‚Üí `0011_past_drax.sql`
- [x] Appliquer les migrations (`make db-migrate`)
- [x] V√©rifier le sch√©ma - toutes les tables cr√©√©es avec succ√®s

### Phase 2 : API Backend - Architecture streaming et chat

#### Phase 2A - Streaming complet pour g√©n√©ration d'entreprise (POC)
**Objectif** : Impl√©menter le streaming complet (OpenAI + DB + NOTIFY) sur un seul cas simple (entreprise) pour valider l'architecture avant g√©n√©ralisation.

**Flux actuel** :
- `POST /api/v1/companies/ai-enrich` ‚Üí appelle directement `enrichCompany` (sans queue)
- Queue `processCompanyEnrich` ‚Üí appelle `enrichCompany` puis met √† jour DB

**Flux cible** :
- M√™me comportement final (r√©sultat JSON pars√©, DB mise √† jour)
- **+ Streaming** : √©v√©nements √©crits dans `chat_stream_events` pendant l'ex√©cution
- **+ NOTIFY** : PostgreSQL NOTIFY pour temps r√©el
- **+ Queue compatible** : la queue attend toujours le r√©sultat final de `enrichCompany`

**T√¢ches** :
- [ ] **2A.1 - Couche OpenAI Streaming** :
  - Cr√©er `callOpenAIStream` dans `api/src/services/openai.ts` :
    - Retourne `AsyncIterable<StreamEvent>` o√π `StreamEvent` = `{ type: 'reasoning_delta' | 'content_delta' | 'tool_call_start' | 'tool_call_delta' | 'tool_call_result' | 'done', data: any }`
    - G√®re reasoning, content, tool_calls en streaming
    - Mutualise les valeurs par d√©faut du mod√®le (via `settingsService.getAISettings().defaultModel`)
    - Garde `callOpenAI` pour compatibilit√© (g√©n√©rations classiques actuelles)
  
- [ ] **2A.2 - Service Stream Partag√© (base)** :
  - Cr√©er `api/src/services/stream-service.ts` :
    - Fonction `writeStreamEvent(streamId, eventType, data, sequence)` :
      - √âcrit dans `chat_stream_events` (avec `message_id=null` pour g√©n√©rations classiques)
      - PostgreSQL NOTIFY avec payload minimal (`stream_id`, `sequence`)
      - Gestion des s√©quences (auto-incr√©ment par `stream_id`)
    - Fonction `generateStreamId(promptId?, jobId?)` : g√©n√®re `stream_id` unique
      - Pour g√©n√©rations classiques : `prompt_id` + timestamp (ou `job_id` si disponible)
      - Pour chat : `message_id` (sera utilis√© plus tard)
  
- [ ] **2A.3 - Adapter enrichCompany pour streaming** :
  - Modifier `api/src/services/context-company.ts` :
    - `enrichCompany` accepte un param√®tre optionnel `streamId?: string`
    - Utilise `callOpenAIStream` au lieu de `executeWithTools` ‚Üí `callOpenAI`
    - **Collecte le r√©sultat final** : agr√®ge tous les `content_delta` pour reconstruire le JSON complet
    - **√âcrit les √©v√©nements** : appelle `writeStreamEvent` pour chaque √©v√©nement de streaming
    - **Retourne le r√©sultat final** : parse le JSON comme avant (compatibilit√©)
    - G√®re les tool calls (web_search, web_extract) en streaming
  
- [ ] **2A.4 - Int√©gration queue** :
  - Modifier `queue-manager.ts` ‚Üí `processCompanyEnrich` :
    - G√©n√®re un `streamId` (ex: `company_enrich_${jobId}_${timestamp}`)
    - Passe le `streamId` √† `enrichCompany`
    - La queue attend toujours le r√©sultat final (comportement inchang√©)
    - Met √† jour la DB comme avant
  
- [ ] **2A.5 - Endpoint SSE pour g√©n√©rations classiques** (optionnel pour cette phase) :
  - Cr√©er `GET /api/v1/stream/:stream_id` (SSE) :
    - Lecture des √©v√©nements depuis `chat_stream_events`
    - Support du param√®tre `?since=seq` pour rehydratation
    - Abonnement PostgreSQL NOTIFY pour temps r√©el
  - **Note** : Cet endpoint servira aussi pour le chat plus tard

- [ ] **2A.6 - Tests et validation** :
  - Test unitaire : `callOpenAIStream` retourne bien un AsyncIterable
  - Test unitaire : `writeStreamEvent` √©crit bien en DB et NOTIFY
  - Test int√©gration : `enrichCompany` avec streaming retourne le m√™me r√©sultat qu'avant
  - Test int√©gration : √©v√©nements √©crits dans `chat_stream_events` avec `message_id=null`
  - Test queue : `processCompanyEnrich` fonctionne toujours (r√©sultat final + DB mise √† jour)
  - Test E2E : enrichissement d'entreprise fonctionne (endpoint `/ai-enrich` et via queue)

**Crit√®res de validation Phase 2A** :
- ‚úÖ Les g√©n√©rations d'entreprise fonctionnent toujours (comportement final identique)
- ‚úÖ Les √©v√©nements de streaming sont √©crits dans `chat_stream_events`
- ‚úÖ PostgreSQL NOTIFY fonctionne
- ‚úÖ La queue continue de fonctionner normalement
- ‚úÖ Un seul test UAT complet suffit

#### Phase 2B - G√©n√©ralisation aux autres g√©n√©rations classiques
- [x] Adapter `generateUseCaseList` pour utiliser le streaming
- [x] Adapter `generateUseCaseDetail` pour utiliser le streaming
- [x] Adapter `generateExecutiveSummary` pour utiliser le streaming
- [x] Tous utilisent le m√™me tronc commun (orchestrateur `executeWithToolsStream`) + persistance dans `chat_stream_events`
- [x] Int√©gration UI sur les vues dossiers / cas d'usage (SSE, sans polling)

#### Phase 2C - Service Chat
- [x] Cr√©er `api/src/services/chat-service.ts` :
  - Gestion des sessions (cr√©ation, r√©cup√©ration, mise √† jour)
  - Cr√©ation de messages (user et assistant)
  - Int√©gration avec streaming (via job `chat_message` en queue pour pr√©parer le scaling / workers d√©di√©s)
  - Utilisation du mod√®le par d√©faut depuis settings

#### Phase 2D - Endpoints Chat
- [x] Cr√©er le router `/api/v1/chat` dans `api/src/routes/api/chat.ts`
- [x] Impl√©menter `POST /api/v1/chat/messages` :
  - Cr√©ation de session si n√©cessaire
  - Enregistrement du message utilisateur
  - Enfile un job `chat_message` (pr√©pare le scaling / workers d√©di√©s)
  - Enregistrement du message assistant avec reasoning
- [x] Impl√©menter `GET /api/v1/chat/sessions` et `GET /api/v1/chat/sessions/:id/messages`
- [x] Option C (historique complet tools/reasoning) :
  - API : `GET /api/v1/chat/messages/:id/stream-events` (lecture `chat_stream_events`, `streamId = messageId`)
  - UI : rehydratation des √©tapes tools/reasoning des derniers messages assistant lors du chargement d'une session
  - Optimisation : endpoint batch `GET /api/v1/chat/sessions/:id/stream-events` (1 call/session au lieu de N calls/message)
- [x] **Streaming** : pas d'endpoint d√©di√© `GET /api/v1/chat/stream/:stream_id`.
  - Le client utilise le **SSE global** `GET /api/v1/streams/sse` et filtre par `streamId`
  - `streamId` du chat = `assistantMessageId` (retourn√© par `POST /chat/messages`)
- [x] Monter le router dans `api/src/routes/api/index.ts`
- [x] Mettre √† jour OpenAPI (`api/src/openapi/`) (minimal : endpoints chat)

#### Phase 2E - Tool Service
- [x] Cr√©er `api/src/services/tool-service.ts` :
  - Ex√©cution d'un tool **g√©n√©rique** `update_usecase_field` (usecase uniquement, champs `use_cases.data.*`)
  - Validation des modifications
  - √âcriture dans `context_modification_history`
  - Snapshots avant/apr√®s dans `chat_contexts`
  - Feature d'annulation du dernier changement au niveau de l'objet

### Phase 3 : UI SvelteKit - Composants de base
- [x] **Unifier le widget flottant global (1 seule bulle)** :
  - Cr√©er `ui/src/lib/components/ChatWidget.svelte`
    - Contient **la bulle** (bouton fixed) + **le panneau** (drawer)
    - Header avec switch de vue: **Chat** ‚Üî **QueueMonitor**
    - La bulle refl√®te un √©tat global (jobs en cours/failed + conversations en cours/erreurs)
  - Remplacer l‚Äôinjection de `QueueMonitor` dans `ui/src/routes/+layout.svelte` par ce widget unique
- [x] **Ergonomie de la bulle & du panneau (it√©rations)** :
  - Bulle = **ic√¥ne chat** (toujours visible), avec **badge montre** si jobs IA actifs (`pending/processing`)
  - Le statut ‚Äúmontre‚Äù se **r√©initialise** automatiquement d√®s qu‚Äôil n‚Äôy a plus de jobs actifs (fin/purge)
  - Fen√™tre plus haute (**~70vh**), ancr√©e en bas √† droite, et **recouvre** l‚Äôemplacement de la bulle (bulle cach√©e pendant l‚Äôouverture)
  - Fix layout: wrapper en `flex flex-col` + content `flex-1 min-h-0` pour conserver le composer visible en bas
- [x] **QueueMonitor r√©utilis√© comme panel** (sans requalifier) :
  - `QueueMonitor` conserve le contenu existant, mais **sans bulle/wrapper fixed/header**
  - Le titre et le bouton poubelle sont d√©plac√©s dans le header du widget
- [x] **UI Chat (vue dans le widget)** :
  - [x] `ChatPanel.svelte` : liste sessions + messages + composer (envoi `POST /chat/messages`)
  - [x] Streaming c√¥t√© UI : r√©sum√© en gris (dur√©e + nb d'outils) + chevron + d√©tail (raisonnement/outils sans r√©sultat), stream du r√©sultat dans la bulle, puis refresh messages au `done/error` (**scroll coll√© en bas**)
  - [x] UX: d√®s `status: started`, afficher un loader "En cours‚Ä¶" dans la zone grise (avant reasoning/outils/r√©ponse)
  - [x] D√©placer la s√©lection de session dans le header du widget (`ChatWidget`) + actions **+** (nouvelle session locale) et **üóëÔ∏è** (supprimer conversation)
  - [x] API : `DELETE /api/v1/chat/sessions/:id` (cascade DB)
  - Streaming: r√©utiliser `streamHub` + `StreamMessage` (pas de 2·µâ composant de rendu)
    - `streamId` = `assistantMessageId`
    - `StreamMessage` est la brique unique pour afficher l‚Äôavancement (reasoning/tools/content) + historique
- [x] **Data fetch (non-streaming)** :
  - `GET /chat/sessions` + `GET /chat/sessions/:id/messages` pour recharger l‚Äôhistorique apr√®s refresh
  - SSE global `/streams/sse` seulement pour les messages en cours / nouveaux events (cache/replay = confort UX)

#### Convergence StreamMessage (Chat vs Jobs) ‚Äî analyse de r√©trofit
- **Constat** :
  - Le `ChatPanel` a aujourd'hui **l'ergonomie cible** (zone grise steps, r√©sum√© ‚ÄúRaisonnement X, N outils‚Äù, chevron + d√©tail).
  - `StreamMessage.svelte` existe d√©j√†, mais il est plut√¥t ‚Äújob progress compact‚Äù (√©tape + historique), et ne porte pas l'UX Chat.
- **Diff√©rences r√©elles Chat vs Job (faibles)** :
  - **Chat**: rendu du **r√©sultat** dans une bulle + remplacement par le contenu final quand `done`.
  - **Jobs**: pas de bulle de r√©ponse (ou pas toujours), mais on veut **la m√™me lecture** des steps (reasoning/tools) + historique.
  - **Hydratation historique**:
    - Chat: scopes user/session (endpoints `/chat/*`).
    - Jobs: scope ‚ÄústreamId‚Äù (ex: `job_<id>`, `company_<id>`), n√©cessite un endpoint g√©n√©rique `/streams/*`.
- **Plan (5 √©tapes)** :
  - [x] (1) Documenter cette convergence (section actuelle).
  - [x] (2) Remplacer `StreamMessage` par une version unifi√©e qui reprend l'UX du chat (backup: `StreamMessageLegacy.svelte`).
  - [x] (3) API: permettre la relecture d'historique par `streamId` (jobs inclus) avec `limit/since` (`GET /api/v1/streams/events/:streamId`).
  - [x] (4) Adapter `StreamMessage` au besoin QueueMonitor (variant `job`: steps + historique, sans bulle chat).
  - [x] (5) Adapter `QueueMonitor` pour utiliser `StreamMessage` (live SSE + historique API via `historySource="stream"`).

### Phase 4 : Int√©gration UI dans les vues existantes
- [ ] **Chat global (pas page-scoped)** :
  - Le chat doit √™tre disponible **partout** (comme la bulle QueueMonitor)
  - Ajout d‚Äôun s√©lecteur de contexte (company/folder/usecase) dans le header du widget (optionnel au d√©but)
- [ ] **ContextBadge** :
  - Badge indiquant le contexte courant (folder/usecase/company) + lien vers l‚Äôobjet
  - Visible dans le header du ChatPanel (et dans les messages si besoin)
- [ ] **UndoBar** :
  - Bouton "Annuler" + preview de la derni√®re modification (via `context_modification_history` + `chat_contexts`)
  - Option: confirmation humaine pour actions ‚ö†Ô∏è
- [ ] **Avant/Apr√®s** :
  - Afficher diff (JSON patch / champ cibl√©) dans le ChatPanel ou une modale

### Phase 5 : Tests
- [ ] Tests unitaires API :
  - Agr√©gation SSE (deltas reasoning/content)
  - Application de deltas
- Tool-call `update_usecase_field`
  - Validation des modifications
- [ ] Tests d'int√©gration API :
  - POST message ‚Üí SSE ‚Üí update description ‚Üí lecture DB
  - V√©rification `context_modification_history`
  - V√©rification snapshots dans `chat_contexts`
- [ ] Tests E2E Playwright :
  - Parcours "demande d'am√©lioration" sur un use case puis annulation
  - V√©rification description mise √† jour
  - V√©rification historique visible
  - Test de l'annulation du dernier changement

### Phase 6 : Documentation et finalisation
- [ ] Mettre √† jour la documentation OpenAPI
- [ ] V√©rifier que tous les tests passent (`make test`)
- [ ] V√©rifier le build (`make build`)
- [ ] Ex√©cuter les tests E2E (`make test-e2e`)
- [ ] V√©rifier CI GitHub Actions

## D√©cisions techniques

- **Parcours impl√©ment√©** : Use case uniquement (folder sera ajout√© ult√©rieurement)
- **Mod√®le OpenAI** : `gpt-4.1-nano` par d√©faut, r√©cup√©r√© via `settingsService.getAISettings().defaultModel`
- **Interface utilisateur** : Popup flottant similaire √† `QueueMonitor.svelte`, avec la queue en accord√©on dans le m√™me conteneur
- **Validation** : Pas de confirmation interm√©diaire. Feature d'annulation du dernier changement au niveau de l'objet (√† terme √† la maille du sous-objet `data.description`)

## Architecture & Incoh√©rences identifi√©es avec le plan initial

### Incoh√©rences identifi√©es

1. **Phase 2 vs Phase 3** : Le plan initial met "Service de streaming" en Phase 3, mais la couche streaming doit √™tre pr√™te AVANT les endpoints chat (Phase 2), car ils en d√©pendent.

2. **Queue pour chat** : le plan initial disait "direct sans queue", mais on a choisi un job `chat_message` pour pr√©parer le scaling (workers d√©di√©s). Le streaming reste en temps r√©el via `chat_stream_events` + SSE global.

3. **Architecture streaming** : Il faut une **couche streaming partag√©e** qui sert :
   - Les g√©n√©rations classiques (via queue) - qui deviendront plus transparentes pour tools/r√©flexion
   - Le chat (via queue `chat_message`, scalable)
   - M√©thodes partag√©es pour √©viter la duplication

### Approche progressive valid√©e

**Phase 2A - POC sur g√©n√©ration d'entreprise** :
- Cas le plus simple (pas de tool calls complexes, pas de multi-√©tapes)
- Permet de valider l'architecture compl√®te (streaming + DB + NOTIFY + queue)
- **Un seul test UAT complet** suffit avant g√©n√©ralisation
- G√©n√©ralisation ensuite (Phase 2B) aux autres g√©n√©rations classiques

**Gestion de la queue** :
- La queue continue de fonctionner normalement
- Elle attend toujours le r√©sultat final de `enrichCompany` (comportement inchang√©)
- Le streaming est transparent : √©v√©nements √©crits pendant l'ex√©cution, r√©sultat final collect√© et retourn√©

**R√©cup√©ration du r√©sultat final** :
- `enrichCompany` agr√®ge tous les `content_delta` pour reconstruire le JSON complet
- Parse le JSON comme avant (compatibilit√© totale)
- Retourne le r√©sultat final (comme avant)
- La queue met √† jour la DB avec ce r√©sultat (comportement inchang√©)

## Commits & Progress

- [x] **Phase 1** : Ajout des tables chat dans le sch√©ma Drizzle
  - Tables cr√©√©es : `chat_sessions`, `chat_messages`, `chat_contexts`, `chat_stream_events`, `context_modification_history`
  - Migration g√©n√©r√©e : `0011_past_drax.sql`
  - Migration appliqu√©e avec succ√®s
  - V√©rification : toutes les tables pr√©sentes en base

- [x] **Phase 2A (POC streaming entreprise + UI monitoring)** : Streaming end-to-end + affichage temps r√©el
  - **API**
    - SSE global : `GET /api/v1/streams/sse` (flux unique) + `LISTEN/NOTIFY` (`stream_events`, `job_events`, `company_events`)
    - `generateStreamId` d√©terministe pour jobs (`job_<jobId>`) + **enrich entreprise streamId** : `company_<companyId>`
    - `NOTIFY job_events` (queue) + `NOTIFY company_events` (CRUD + transitions de statut)
    - Typage ‚Äúsafe‚Äù sur `executeWithToolsStream` (`event.data` = `unknown`) pour √©viter les r√©gressions TS/ESLint
    - Compat OpenAI : d√©sactivation de `reasoning.summary` pour les mod√®les `gpt-4.1-*` (ex: `gpt-4.1-nano-*`) pour √©viter un 400
  - **UI**
    - Nouveau composant `StreamMessage` (prop `streamId`) : derni√®re √©tape + historique d√©pliable, deltas cumul√©s, auto-scroll bas, placeholder sans waiter
    - `streamHub` : connexion SSE unique + abonnements cibl√©s (`setStream`, `setJobUpdates`) + cache/replay + agr√©gation des deltas
    - `QueueMonitor` : bouton toujours √† jour (job_update m√™me repli√©) + suivi de stream via `StreamMessage`
    - Liste entreprises : remplacement du waiter en mode `enriching` par `StreamMessage` sur `company_<id>`
    - Raffinements `StreamMessage` : chevron sur la ligne du titre + scrollbar discr√®te (zones scrollables)

- [x] **Phase 2A.1** : Couche OpenAI Streaming
  - Cr√©√© `callOpenAIStream` dans `openai.ts`
  - Retourne `AsyncIterable<StreamEvent>`
  - G√®re content_delta, tool_call_start, tool_call_delta, status, error, done
  - Mutualise les valeurs par d√©faut du mod√®le via `settingsService.getAISettings().defaultModel`

- [x] **Phase 2A.2** : Service Stream Partag√©
  - Cr√©√© `stream-service.ts` avec `writeStreamEvent`, `generateStreamId`, `getNextSequence`, `readStreamEvents`
  - √âcriture dans `chat_stream_events` avec `message_id=null` pour g√©n√©rations classiques
  - PostgreSQL NOTIFY pour temps r√©el (payload minimal)

- [x] **Phase 2A.3** : Adapter enrichCompany pour streaming
  - Cr√©√© `enrichCompanyStream` qui utilise `callOpenAIStream`
  - Collecte le r√©sultat final (agr√®ge content_delta)
  - G√®re les tool calls (web_search, web_extract) en streaming
  - √âcrit tous les √©v√©nements dans `chat_stream_events`
  - `enrichCompany` accepte maintenant `streamId?` optionnel

- [x] **Phase 2A.4** : Int√©gration queue
  - Modifi√© `processCompanyEnrich` pour g√©n√©rer un `streamId` et le passer √† `enrichCompany`
  - La queue attend toujours le r√©sultat final (comportement inchang√©)

- [x] **Phase 2B (streaming dossiers + cas d'usage + synth√®se)** : G√©n√©ralisation aux g√©n√©rations classiques
  - **API**
    - Jobs : `use_case_list`, `use_case_detail`, `executive_summary` passent par `executeWithToolsStream`
    - `streamId` d√©terministes par entit√© : `folder_<folderId>`, `usecase_<useCaseId>`
    - √âv√©nements temps r√©el : `NOTIFY folder_events/usecase_events` + SSE `folder_update/usecase_update`
  - **UI**
    - Vues `/dossiers` et `/cas-usage` (liste + d√©tail) : suivi via SSE + `StreamMessage` (plus de polling)
    - Ergonomie cartes : suppression des badges jaunes ‚ÄúG√©n√©ration‚Ä¶‚Äù, `StreamMessage` plac√© aux bons endroits
    - Dossiers : masque le compteur ‚Äú0 cas d‚Äôusage‚Äù pendant la g√©n√©ration, et ‚ÄúS√©lectionn√©‚Äù affich√© dans le footer (pas dans le corps)

## Status
- **Progress**: Phase 1 + Phase 2A (POC entreprise) + Phase 2B ‚úÖ
- **Current**: Phase 3 - Widget global Chat/Queue + UI chat
- **Next**:
  - UI : compl√©ter `ChatPanel` (sessions/messages/composer) + branchement aux endpoints `/api/v1/chat/*`
  - UI : afficher le stream chat via `StreamMessage` (streamId = assistantMessageId)
  - Int√©grer le tool `update_usecase_field` dans la boucle chat (tool calling) + UndoBar
  - Garder la SSE globale unique + filtrage c√¥t√© UI (pas de polling)

## Scope
- **API** : Nouveaux endpoints chat, streaming SSE, tools
- **UI** : Nouveaux composants chat-stream, int√©gration dans vues existantes
- **DB** : Nouvelles tables pour chat, streaming, historique
- **Tests** : Unit, int√©gration, E2E pour le parcours complet
- **CI** : V√©rification que les tests passent dans GitHub Actions

## R√©f√©rences
- Sp√©cification compl√®te : `spec/SPEC_CHATBOT.md`
- Lot A d√©taill√© : `spec/SPEC_CHATBOT.md` lignes 800-818
- Mod√®le de donn√©es : `spec/SPEC_CHATBOT.md` lignes 228-426
- Architecture streaming : `spec/SPEC_CHATBOT.md` lignes 119-138
- Composants UI : `spec/SPEC_CHATBOT.md` lignes 146-203
